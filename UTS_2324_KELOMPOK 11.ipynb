{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Tugas Besar Pengganti Ujian Tengah Semester (UTS), Semester Genap 2023/2024**\n",
    "### Deadline: 1 Mei 2024, Pukul 5 Sore\n",
    "##### Dosen: DKT, ITQ, HUE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "***'Dengan ini kami menyatakan bahwa tugas ini dibuat sebenar-benarnya hasil kerjasama kami dalam kelompok. Kami menjunjung tinggi aspek kejujuran sehingga kami dapat pastikan hasil ini bukan berasal dari meniru/mencontek/meminta hasil/berdiskusi dengan kelompok lain, baik dalam satu kelas yang sama maupun berbeda'***\n",
    "\n",
    "---\n",
    "Bandung, 24 April 2024\n",
    "\n",
    "> Kelompok: 11\n",
    ">\n",
    "> Anggota:\n",
    "> 1. Ananda Rafi Amanullah, 1102213017 [25% bagian A]\n",
    "> 2. Daffa Sahrul Rahman  , 1102210224 [25% bagian B]\n",
    "> 3. Ghanendra Amru Kumara, 1102213207 [25% bagian B]\n",
    "> 4. Muhammad Ibrahim, 1102213157 [25% bagian A]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Penjelasan (harus dibaca dan dimengerti)**:\n",
    "* Tugas besar harus dikerjakan menggunakan bahasa pemrograman `Python` dan *library* `Scikit-Learn`. Sebagai dasar, lihat **A.2. Dasar-dasar *Applications Programming Interface* (API) dari *Scikit-Learn*** pada **Chapter 3**\n",
    "* Pada setiap bagian jawaban, anda bisa menambahkan cell `code` untuk kode maupun cell `Markdown` untuk penjelasan, sesuai dengan kebutuhan masing-masing.\n",
    "* Dikumpulkan sesuai dengan tenggat waktu, setiap keterlambatan akan diberikan hukuman pengurangan 10 poin setiap kelipatan 15 menit.\n",
    "* Dikerjakan dengan `Jupyter Lab` atau `Jupyter Notebook`, dan dikumpulkan dalam bentuk file dengan extension `.ipynb` yang digunakan pada `Jupyter Notebook/Jupyter Lab` (tidak boleh dalam format lain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Metode Regresi (40 %)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate dataset sintentik sesuai dengan nomer kelompok ganjil dan genap dan mengubah \"variable_dataset\" sesuai dengan jumlah nim akhir dari setiap anggota, misalkan nim anggota 11590012, 115090009, 115090009, jadi variable_dataset adalah 2+9+9 = 20:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Kelompok Ganjil "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "n_samples = 500\n",
    "variable_dataset = 25 #Ubah sesuai ketentuan diatas\n",
    "rng = np.random.RandomState(0)\n",
    "X = rng.randn(n_samples, 3)\n",
    "noise = rng.normal(loc=0.0, scale=0.01, size=n_samples)\n",
    "y = 5 * X[:, 0] + np.sin(variable_dataset * np.pi * X[:, 0]) - noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Kelompok Genap "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "\n",
    "variable_dataset = 20 #Ubah sesuai ketentuan diatas\n",
    "X, y = make_regression(n_samples=500, n_features=3, noise=variable_dataset, random_state=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pada soal ini langkah pekerjaan difokuskan untuk mencari fitur mana yang paling berpengaruh untuk memprediksi **output(y)** dengan menggunakan 3 metode regresi.\n",
    "\n",
    "Training data satu fitur satu persatu dengan menggunakan 3 metode regresi:\n",
    "1. Regressi Linier\n",
    "2. Regressi Polinomial\n",
    "3. Regressi Dicision Tree \n",
    "\n",
    "Lakukan training untuk dengan 3 metode itu berulang kali dengan mencari hyperparameter terbaiknya masing-masing metode. Seperti penjelasan dibawah ini:\n",
    "1. Regressi Linier dengan hyperparameter learning rate (alpa) dan fit_intercept.\n",
    "2. Regressi Polinomial dengan hyperparameter orde, learning rate (alpa) dan fit_intercept.\n",
    "3. Regressi Dicision Tree dengan hyperparameter max_dept dan criteria impurity.\n",
    "\n",
    "Berikut poin-poin penilaian untuk soal:\n",
    "1. Implementasi code untuk process training benar `(40%)`.\n",
    "2. Process perncarian hyperparameter yang tepat untuk setiap metode`(10%)`.\n",
    "3. Penentuan fitur terbaik, hyperparameter terbaik, model/metode terbaik bedasarkan hasil model setiap process training dengan melihat ukuran kinerja regresi MSE,RMSE, R2 (score model regresi)`(30%)`.\n",
    "4. Analisis fitur terbaik, hyperparameter terbaik, model/metode terbaik yang dilakukan`(10%) `."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Langkah Pengerjaan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset sesuai ketentuan diatas\n",
    "# Perhatikan data kelompok. Data menyesuaikan dengan dengan nomor kelompok\n",
    "# generate dataset sesuai code diatas.\n",
    "\n",
    "##contoh\n",
    "#import library\n",
    "import numpy as np\n",
    "#mendefinisikan paramter untuk datasetnya\n",
    "n_samples = 500\n",
    "variable_dataset = 25 #Ubah sesuai ketentuan diatas [7+4+7+7]\n",
    "rng = np.random.RandomState(0)\n",
    "#membangkitkan dataset\n",
    "X = rng.randn(n_samples, 3)\n",
    "noise = rng.normal(loc=0.0, scale=0.01, size=n_samples)\n",
    "y = 5 * X[:, 0] + np.sin(variable_dataset * np.pi * X[:, 0]) - noise\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C. Buat 3 plot dengan fitur satu, fitur dua dan fitur 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Contoh fitur 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x205ef36b620>]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_feature_satu = X[:,:1] #ambil kolom pertama\n",
    "plt.xlabel(\"Fitur 1\")\n",
    "plt.ylabel(\"Output\")\n",
    "plt.plot(X_feature_satu, y, \"r.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Plot fitur 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x205ef7a0530>]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_feature_dua = X[:,1:2] #ambil kolom kedua\n",
    "plt.xlabel(\"Fitur 2\")\n",
    "plt.ylabel(\"Output\")\n",
    "plt.plot(X_feature_dua, y, \"b.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Plot fitur 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x205ef731730>]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_feature_tiga = X[:,2:3] #ambil kolom ketiga\n",
    "plt.xlabel(\"Fitur 3\")\n",
    "plt.ylabel(\"Output\")\n",
    "plt.plot(X_feature_tiga, y, \"g.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D. Pemilihan Fitur Terbaik dengan 3 model Regresi.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q1. process training dengan **fitur 1 dan output** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_feature_satu = X[:,:1] #ambil kolom pertama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning Rate: 0.001, Fit Intercept: True\n",
      "MSE: 0.4672159395984679, RMSE: 0.6835319594565187, R2 Score: 0.9811388106930359\n",
      "---------------------------------------------------\n",
      "Learning Rate: 0.001, Fit Intercept: False\n",
      "MSE: 0.46898780223540293, RMSE: 0.6848268410594045, R2 Score: 0.9810672818050235\n",
      "---------------------------------------------------\n",
      "Learning Rate: 0.01, Fit Intercept: True\n",
      "MSE: 0.4672159395984679, RMSE: 0.6835319594565187, R2 Score: 0.9811388106930359\n",
      "---------------------------------------------------\n",
      "Learning Rate: 0.01, Fit Intercept: False\n",
      "MSE: 0.46898780223540293, RMSE: 0.6848268410594045, R2 Score: 0.9810672818050235\n",
      "---------------------------------------------------\n",
      "Learning Rate: 0.1, Fit Intercept: True\n",
      "MSE: 0.4672159395984679, RMSE: 0.6835319594565187, R2 Score: 0.9811388106930359\n",
      "---------------------------------------------------\n",
      "Learning Rate: 0.1, Fit Intercept: False\n",
      "MSE: 0.46898780223540293, RMSE: 0.6848268410594045, R2 Score: 0.9810672818050235\n",
      "---------------------------------------------------\n",
      "Model Terbaik:\n",
      "Learning Rate: 0.001, Fit Intercept: True\n",
      "MSE: 0.4672159395984679, RMSE: 0.6835319594565187, R2 Score: 0.9811388106930359\n"
     ]
    }
   ],
   "source": [
    "#Regresi Linier\n",
    "#Import library metode machine learning.\n",
    "import warnings\n",
    "import numpy as np #operasi numerik\n",
    "import pandas as pd #analisis data\n",
    "import matplotlib.pyplot as plt #visualisasi\n",
    "from sklearn.linear_model import LinearRegression #regresi linier\n",
    "from sklearn.model_selection import train_test_split #membagi data\n",
    "from sklearn.metrics import mean_squared_error, r2_score #menghitung metrik\n",
    "\n",
    "#Siapkan data yang akan ditraining fitur satu \"X_feature_satu\" dan output \n",
    "X_feature_satu = X[:,:1]\n",
    "y = y\n",
    "\n",
    "#split data training dan testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_feature_satu, y, test_size=0.2, random_state=42) #test size 20% argument, dengan random state 42\n",
    "\n",
    "# Inisialisasi list untuk menyimpan hasil evaluasi kinerja setiap model\n",
    "mse_scores = [] #mean squared error\n",
    "rmse_scores = [] #root mean squared error\n",
    "r2_scores = [] #r-squared\n",
    "\n",
    "# Hyperparameter yang akan dieksplorasi\n",
    "learning_rates= [0.001, 0.01, 0.1]\n",
    "fit_intercepts = [True, False]\n",
    "\n",
    "#mencoba looping\n",
    "for lr in learning_rates:\n",
    "    for intercept in fit_intercepts:\n",
    "        model = LinearRegression(fit_intercept=intercept)\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "        rmse = np.sqrt(mse)\n",
    "        \n",
    "        try:\n",
    "            r2 = r2_score(y_test, y_pred)\n",
    "        except UndefinedMetricWarning as e: # type: ignore\n",
    "            msg = \"R^2 score is not well-defined with less than two samples.\"\n",
    "            warnings.warn(msg, UndefinedMetricWarning) # type: ignore\n",
    "            r2 = float(\"nan\")\n",
    "        \n",
    "        mse_scores.append(mse)\n",
    "        rmse_scores.append(rmse)\n",
    "        r2_scores.append(r2)\n",
    "        \n",
    "        print(f\"Learning Rate: {lr}, Fit Intercept: {intercept}\")\n",
    "        print(f\"MSE: {mse}, RMSE: {rmse}, R2 Score: {r2}\")\n",
    "        print(\"---------------------------------------------------\")\n",
    "\n",
    "#ukur kinerja setiap model pada setiap trainig dengan MSE,RMSE, R2.\n",
    "best_model_index = np.argmax(r2_scores)\n",
    "\n",
    "# Mendapatkan hyperparameter dari model terbaik\n",
    "best_lr_index = best_model_index // len(fit_intercepts)\n",
    "best_intercept_index = best_model_index % len(fit_intercepts)\n",
    "best_lr = learning_rates[best_lr_index]\n",
    "best_intercept = fit_intercepts[best_intercept_index]\n",
    "\n",
    "# Menampilkan model terbaik\n",
    "print(\"Model Terbaik:\")\n",
    "print(f\"Learning Rate: {best_lr}, Fit Intercept: {best_intercept}\")\n",
    "print(f\"MSE: {mse_scores[best_model_index]}, RMSE: {rmse_scores[best_model_index]}, R2 Score: {r2_scores[best_model_index]}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Orde: 1, Learning Rate: 0.001, Fit Intercept: True\n",
      "MSE: 0.46721593959846786, RMSE: 0.6835319594565187, R2 Score: 0.9811388106930359\n",
      "---------------------------------------------------\n",
      "Orde: 1, Learning Rate: 0.001, Fit Intercept: False\n",
      "MSE: 0.46721593959846763, RMSE: 0.6835319594565185, R2 Score: 0.9811388106930359\n",
      "---------------------------------------------------\n",
      "Orde: 1, Learning Rate: 0.01, Fit Intercept: True\n",
      "MSE: 0.46721593959846786, RMSE: 0.6835319594565187, R2 Score: 0.9811388106930359\n",
      "---------------------------------------------------\n",
      "Orde: 1, Learning Rate: 0.01, Fit Intercept: False\n",
      "MSE: 0.46721593959846763, RMSE: 0.6835319594565185, R2 Score: 0.9811388106930359\n",
      "---------------------------------------------------\n",
      "Orde: 1, Learning Rate: 0.1, Fit Intercept: True\n",
      "MSE: 0.46721593959846786, RMSE: 0.6835319594565187, R2 Score: 0.9811388106930359\n",
      "---------------------------------------------------\n",
      "Orde: 1, Learning Rate: 0.1, Fit Intercept: False\n",
      "MSE: 0.46721593959846763, RMSE: 0.6835319594565185, R2 Score: 0.9811388106930359\n",
      "---------------------------------------------------\n",
      "Orde: 2, Learning Rate: 0.001, Fit Intercept: True\n",
      "MSE: 0.47310946152163263, RMSE: 0.6878295294050937, R2 Score: 0.9809008932264933\n",
      "---------------------------------------------------\n",
      "Orde: 2, Learning Rate: 0.001, Fit Intercept: False\n",
      "MSE: 0.47310946152163297, RMSE: 0.6878295294050939, R2 Score: 0.9809008932264933\n",
      "---------------------------------------------------\n",
      "Orde: 2, Learning Rate: 0.01, Fit Intercept: True\n",
      "MSE: 0.47310946152163263, RMSE: 0.6878295294050937, R2 Score: 0.9809008932264933\n",
      "---------------------------------------------------\n",
      "Orde: 2, Learning Rate: 0.01, Fit Intercept: False\n",
      "MSE: 0.47310946152163297, RMSE: 0.6878295294050939, R2 Score: 0.9809008932264933\n",
      "---------------------------------------------------\n",
      "Orde: 2, Learning Rate: 0.1, Fit Intercept: True\n",
      "MSE: 0.47310946152163263, RMSE: 0.6878295294050937, R2 Score: 0.9809008932264933\n",
      "---------------------------------------------------\n",
      "Orde: 2, Learning Rate: 0.1, Fit Intercept: False\n",
      "MSE: 0.47310946152163297, RMSE: 0.6878295294050939, R2 Score: 0.9809008932264933\n",
      "---------------------------------------------------\n",
      "Orde: 3, Learning Rate: 0.001, Fit Intercept: True\n",
      "MSE: 0.4750792422882708, RMSE: 0.6892599236052179, R2 Score: 0.9808213745183673\n",
      "---------------------------------------------------\n",
      "Orde: 3, Learning Rate: 0.001, Fit Intercept: False\n",
      "MSE: 0.47507924228827053, RMSE: 0.6892599236052177, R2 Score: 0.9808213745183673\n",
      "---------------------------------------------------\n",
      "Orde: 3, Learning Rate: 0.01, Fit Intercept: True\n",
      "MSE: 0.4750792422882708, RMSE: 0.6892599236052179, R2 Score: 0.9808213745183673\n",
      "---------------------------------------------------\n",
      "Orde: 3, Learning Rate: 0.01, Fit Intercept: False\n",
      "MSE: 0.47507924228827053, RMSE: 0.6892599236052177, R2 Score: 0.9808213745183673\n",
      "---------------------------------------------------\n",
      "Orde: 3, Learning Rate: 0.1, Fit Intercept: True\n",
      "MSE: 0.4750792422882708, RMSE: 0.6892599236052179, R2 Score: 0.9808213745183673\n",
      "---------------------------------------------------\n",
      "Orde: 3, Learning Rate: 0.1, Fit Intercept: False\n",
      "MSE: 0.47507924228827053, RMSE: 0.6892599236052177, R2 Score: 0.9808213745183673\n",
      "---------------------------------------------------\n",
      "Orde: 4, Learning Rate: 0.001, Fit Intercept: True\n",
      "MSE: 0.47868798499591925, RMSE: 0.6918728098400162, R2 Score: 0.9806756920328177\n",
      "---------------------------------------------------\n",
      "Orde: 4, Learning Rate: 0.001, Fit Intercept: False\n",
      "MSE: 0.47868798499591997, RMSE: 0.6918728098400168, R2 Score: 0.9806756920328177\n",
      "---------------------------------------------------\n",
      "Orde: 4, Learning Rate: 0.01, Fit Intercept: True\n",
      "MSE: 0.47868798499591925, RMSE: 0.6918728098400162, R2 Score: 0.9806756920328177\n",
      "---------------------------------------------------\n",
      "Orde: 4, Learning Rate: 0.01, Fit Intercept: False\n",
      "MSE: 0.47868798499591997, RMSE: 0.6918728098400168, R2 Score: 0.9806756920328177\n",
      "---------------------------------------------------\n",
      "Orde: 4, Learning Rate: 0.1, Fit Intercept: True\n",
      "MSE: 0.47868798499591925, RMSE: 0.6918728098400162, R2 Score: 0.9806756920328177\n",
      "---------------------------------------------------\n",
      "Orde: 4, Learning Rate: 0.1, Fit Intercept: False\n",
      "MSE: 0.47868798499591997, RMSE: 0.6918728098400168, R2 Score: 0.9806756920328177\n",
      "---------------------------------------------------\n",
      "Orde: 5, Learning Rate: 0.001, Fit Intercept: True\n",
      "MSE: 0.47811895214471356, RMSE: 0.6914614610697501, R2 Score: 0.9806986635015088\n",
      "---------------------------------------------------\n",
      "Orde: 5, Learning Rate: 0.001, Fit Intercept: False\n",
      "MSE: 0.4781189521447166, RMSE: 0.6914614610697524, R2 Score: 0.9806986635015087\n",
      "---------------------------------------------------\n",
      "Orde: 5, Learning Rate: 0.01, Fit Intercept: True\n",
      "MSE: 0.47811895214471356, RMSE: 0.6914614610697501, R2 Score: 0.9806986635015088\n",
      "---------------------------------------------------\n",
      "Orde: 5, Learning Rate: 0.01, Fit Intercept: False\n",
      "MSE: 0.4781189521447166, RMSE: 0.6914614610697524, R2 Score: 0.9806986635015087\n",
      "---------------------------------------------------\n",
      "Orde: 5, Learning Rate: 0.1, Fit Intercept: True\n",
      "MSE: 0.47811895214471356, RMSE: 0.6914614610697501, R2 Score: 0.9806986635015088\n",
      "---------------------------------------------------\n",
      "Orde: 5, Learning Rate: 0.1, Fit Intercept: False\n",
      "MSE: 0.4781189521447166, RMSE: 0.6914614610697524, R2 Score: 0.9806986635015087\n",
      "---------------------------------------------------\n",
      "Best Model:\n",
      "Orde: 1, Learning Rate: 0.001, Fit Intercept: True\n",
      "MSE: 0.46721593959846786, RMSE: 0.6835319594565187, R2 Score: 0.9811388106930359\n"
     ]
    }
   ],
   "source": [
    "#Regresi Polinomial\n",
    "#Import library metode machine learning.\n",
    "import warnings\n",
    "import numpy as np #operasi numerik\n",
    "import pandas as pd #analisis data\n",
    "import matplotlib.pyplot as plt #visualisasi\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.model_selection import train_test_split #membagi data\n",
    "from sklearn.metrics import mean_squared_error, r2_score #menghitung metrik\n",
    "\n",
    "#Siapkan data yang akan ditraining fitur satu \"X_feature_satu\" dan output \n",
    "X_feature_satu = X[:,:1]\n",
    "y = y\n",
    "\n",
    "#split data training dan testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_feature_satu, y, test_size=0.2, random_state=42) #test size 20% argument, dengan random state 42\n",
    "\n",
    "# Inisialisasi list untuk evaluasi metrik\n",
    "best_model_index = None\n",
    "best_mse = np.inf\n",
    "best_rmse = np.inf\n",
    "best_r2 = -np.inf\n",
    "\n",
    "# Hyperparameter yang akan dieksplorasi\n",
    "ordes = range(1,6) #experiment\n",
    "learning_rates= [0.001, 0.01, 0.1] #experiment\n",
    "fit_intercepts = [True, False]\n",
    "\n",
    "#mencoba looping\n",
    "for order in ordes:\n",
    "    for lr in learning_rates:\n",
    "        for fit_intercept in fit_intercepts:\n",
    "            # membuat polynomial features transformer\n",
    "            poly = PolynomialFeatures(degree=order)\n",
    "\n",
    "            # fitur transform (membuat polynomial terms)\n",
    "            X_train_poly = poly.fit_transform(X_train.reshape(-1, 1))\n",
    "            X_test_poly = poly.transform(X_test.reshape(-1, 1))\n",
    "\n",
    "            # membuat model linear regression\n",
    "            model = LinearRegression(fit_intercept=fit_intercept)\n",
    "            model.fit(X_train_poly, y_train)\n",
    "\n",
    "            # Prediksi\n",
    "            y_pred = model.predict(X_test_poly)\n",
    "\n",
    "            # evaluasi\n",
    "            mse = mean_squared_error(y_test, y_pred)\n",
    "            rmse = np.sqrt(mse)\n",
    "            r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "            # Hasil\n",
    "            print(f\"Orde: {order}, Learning Rate: {lr}, Fit Intercept: {fit_intercept}\")\n",
    "            print(f\"MSE: {mse}, RMSE: {rmse}, R2 Score: {r2}\")\n",
    "            print(\"---------------------------------------------------\")\n",
    "\n",
    "            # Update model terbaik berdasarkan nilai R2\n",
    "            if r2 > best_r2:\n",
    "                best_model_index = (order, lr, fit_intercept)\n",
    "                best_mse = mse\n",
    "                best_rmse = rmse\n",
    "                best_r2 = r2\n",
    "\n",
    "# Detail hasil model terbaik\n",
    "print(\"Best Model:\")\n",
    "print(f\"Orde: {best_model_index[0]}, Learning Rate: {best_model_index[1]}, Fit Intercept: {best_model_index[2]}\")\n",
    "print(f\"MSE: {best_mse}, RMSE: {best_rmse}, R2 Score: {best_r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Depth: 2, Criterion: squared_error\n",
      "MSE: 3.472152940547492, RMSE: 1.8633713909329754, R2 Score: 0.8598315503304947\n",
      "---------------------------------------------------\n",
      "Max Depth: 2, Criterion: friedman_mse\n",
      "MSE: 3.472152940547492, RMSE: 1.8633713909329754, R2 Score: 0.8598315503304947\n",
      "---------------------------------------------------\n",
      "Max Depth: 2, Criterion: absolute_error\n",
      "MSE: 3.4597313897030237, RMSE: 1.8600353194773007, R2 Score: 0.8603329998789946\n",
      "---------------------------------------------------\n",
      "Max Depth: 3, Criterion: squared_error\n",
      "MSE: 1.3126556200914548, RMSE: 1.1457118399019253, R2 Score: 0.94700898653699\n",
      "---------------------------------------------------\n",
      "Max Depth: 3, Criterion: friedman_mse\n",
      "MSE: 1.3126556200914548, RMSE: 1.1457118399019253, R2 Score: 0.94700898653699\n",
      "---------------------------------------------------\n",
      "Max Depth: 3, Criterion: absolute_error\n",
      "MSE: 1.3551654637760664, RMSE: 1.1641157432901879, R2 Score: 0.9452928930966976\n",
      "---------------------------------------------------\n",
      "Max Depth: 4, Criterion: squared_error\n",
      "MSE: 0.6464568592653785, RMSE: 0.8040254095893852, R2 Score: 0.9739029768293681\n",
      "---------------------------------------------------\n",
      "Max Depth: 4, Criterion: friedman_mse\n",
      "MSE: 0.6464568592653785, RMSE: 0.8040254095893852, R2 Score: 0.9739029768293681\n",
      "---------------------------------------------------\n",
      "Max Depth: 4, Criterion: absolute_error\n",
      "MSE: 0.6580348440760072, RMSE: 0.8111934689554688, R2 Score: 0.9734355814671848\n",
      "---------------------------------------------------\n",
      "Max Depth: 5, Criterion: squared_error\n",
      "MSE: 0.4675069308612546, RMSE: 0.6837447848877932, R2 Score: 0.9811270635739225\n",
      "---------------------------------------------------\n",
      "Max Depth: 5, Criterion: friedman_mse\n",
      "MSE: 0.4675069308612546, RMSE: 0.6837447848877932, R2 Score: 0.9811270635739225\n",
      "---------------------------------------------------\n",
      "Max Depth: 5, Criterion: absolute_error\n",
      "MSE: 0.6188170331236471, RMSE: 0.786649244024074, R2 Score: 0.9750187777879544\n",
      "---------------------------------------------------\n",
      "Max Depth: 6, Criterion: squared_error\n",
      "MSE: 0.4061874360667111, RMSE: 0.6373283581221779, R2 Score: 0.9836024898201273\n",
      "---------------------------------------------------\n",
      "Max Depth: 6, Criterion: friedman_mse\n",
      "MSE: 0.4061874360667111, RMSE: 0.6373283581221779, R2 Score: 0.9836024898201273\n",
      "---------------------------------------------------\n",
      "Max Depth: 6, Criterion: absolute_error\n",
      "MSE: 0.546722607287897, RMSE: 0.7394069294291858, R2 Score: 0.9779291806625515\n",
      "---------------------------------------------------\n",
      "Max Depth: 7, Criterion: squared_error\n",
      "MSE: 0.40995839256938815, RMSE: 0.6402799329741548, R2 Score: 0.9834502588741403\n",
      "---------------------------------------------------\n",
      "Max Depth: 7, Criterion: friedman_mse\n",
      "MSE: 0.40995839256938815, RMSE: 0.6402799329741548, R2 Score: 0.9834502588741403\n",
      "---------------------------------------------------\n",
      "Max Depth: 7, Criterion: absolute_error\n",
      "MSE: 0.5213725555930587, RMSE: 0.7220613239836757, R2 Score: 0.9789525449860559\n",
      "---------------------------------------------------\n",
      "Max Depth: 8, Criterion: squared_error\n",
      "MSE: 0.27219585004260805, RMSE: 0.5217239212865441, R2 Score: 0.9890116388994865\n",
      "---------------------------------------------------\n",
      "Max Depth: 8, Criterion: friedman_mse\n",
      "MSE: 0.27219585004260805, RMSE: 0.5217239212865441, R2 Score: 0.9890116388994865\n",
      "---------------------------------------------------\n",
      "Max Depth: 8, Criterion: absolute_error\n",
      "MSE: 0.4154484364969, RMSE: 0.64455289658561, R2 Score: 0.9832286295395133\n",
      "---------------------------------------------------\n",
      "Max Depth: 9, Criterion: squared_error\n",
      "MSE: 0.2702504600163922, RMSE: 0.5198561916688039, R2 Score: 0.9890901729700319\n",
      "---------------------------------------------------\n",
      "Max Depth: 9, Criterion: friedman_mse\n",
      "MSE: 0.2702504600163922, RMSE: 0.5198561916688039, R2 Score: 0.9890901729700319\n",
      "---------------------------------------------------\n",
      "Max Depth: 9, Criterion: absolute_error\n",
      "MSE: 0.35216443833161404, RMSE: 0.5934344431625233, R2 Score: 0.9857833614489657\n",
      "---------------------------------------------------\n",
      "Best Model:\n",
      "Max Depth: 9, Criterion: squared_error\n",
      "MSE: 0.2702504600163922, RMSE: 0.5198561916688039, R2 Score: 0.9890901729700319\n"
     ]
    }
   ],
   "source": [
    "#Decission Tree Regression\n",
    "#Import library metode machine learning.\n",
    "import warnings\n",
    "import numpy as np #operasi numerik\n",
    "import pandas as pd #analisis data\n",
    "import matplotlib.pyplot as plt #visualisasi\n",
    "from sklearn.tree import DecisionTreeRegressor #Decisiion Tree\n",
    "from sklearn.model_selection import train_test_split #membagi data\n",
    "from sklearn.metrics import mean_squared_error, r2_score #menghitung metrik\n",
    "\n",
    "#Siapkan data yang akan ditraining fitur satu \"X_feature_satu\" dan output \n",
    "X_feature_satu = X[:,:1]\n",
    "y = y\n",
    "\n",
    "#split data training dan testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_feature_satu, y, test_size=0.2, random_state=42) #test size 20% argument, dengan random state 42\n",
    "\n",
    "# Inisialisasi list untuk evaluasi metrik\n",
    "best_model_index = None\n",
    "best_mse = np.inf\n",
    "best_rmse = np.inf\n",
    "best_r2 = -np.inf\n",
    "\n",
    "# Hyperparameter yang akan dieksplorasi\n",
    "max_depths = range(2,10) #experiment\n",
    "criterions = ['squared_error', 'friedman_mse', 'absolute_error'] #experiment criteria\n",
    "\n",
    "#mencoba looping\n",
    "for max_depth in max_depths:\n",
    "    for criterion in criterions:\n",
    "        # membuat model decision tree regression\n",
    "        model = DecisionTreeRegressor(max_depth=max_depth, criterion=criterion)\n",
    "\n",
    "        # Melatih model\n",
    "        model.fit(X_train.reshape(-1, 1), y_train)\n",
    "\n",
    "        # Prediksi\n",
    "        y_pred = model.predict(X_test.reshape(-1, 1))\n",
    "\n",
    "        # Evaluasi\n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "        rmse = np.sqrt(mse)\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "        # Hasil\n",
    "        print(f\"Max Depth: {max_depth}, Criterion: {criterion}\")\n",
    "        print(f\"MSE: {mse}, RMSE: {rmse}, R2 Score: {r2}\")\n",
    "        print(\"---------------------------------------------------\")\n",
    "\n",
    "        # Update model terbaik berdasarkan skor R2\n",
    "        if r2 > best_r2:\n",
    "            best_model_index = (max_depth, criterion)\n",
    "            best_mse = mse\n",
    "            best_rmse = rmse\n",
    "            best_r2 = r2\n",
    "\n",
    "# Detail hasil model terbaik\n",
    "print(\"Best Model:\")\n",
    "print(f\"Max Depth: {best_model_index[0]}, Criterion: {best_model_index[1]}\")\n",
    "print(f\"MSE: {best_mse}, RMSE: {best_rmse}, R2 Score: {best_r2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q2. process training dengan **fitur 2 dan output** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_feature_dua = X[:,1:2] #ambil kolom kedua"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning Rate: 0.001, Fit Intercept: True\n",
      "MSE: 24.746714276917416, RMSE: 4.974606946977562, R2 Score: 0.0009919971835179453\n",
      "---------------------------------------------------\n",
      "Learning Rate: 0.001, Fit Intercept: False\n",
      "MSE: 24.693639090000158, RMSE: 4.969269472467775, R2 Score: 0.0031346063351004316\n",
      "---------------------------------------------------\n",
      "Learning Rate: 0.01, Fit Intercept: True\n",
      "MSE: 24.746714276917416, RMSE: 4.974606946977562, R2 Score: 0.0009919971835179453\n",
      "---------------------------------------------------\n",
      "Learning Rate: 0.01, Fit Intercept: False\n",
      "MSE: 24.693639090000158, RMSE: 4.969269472467775, R2 Score: 0.0031346063351004316\n",
      "---------------------------------------------------\n",
      "Learning Rate: 0.1, Fit Intercept: True\n",
      "MSE: 24.746714276917416, RMSE: 4.974606946977562, R2 Score: 0.0009919971835179453\n",
      "---------------------------------------------------\n",
      "Learning Rate: 0.1, Fit Intercept: False\n",
      "MSE: 24.693639090000158, RMSE: 4.969269472467775, R2 Score: 0.0031346063351004316\n",
      "---------------------------------------------------\n",
      "Model Terbaik:\n",
      "Learning Rate: 0.001, Fit Intercept: False\n",
      "MSE: 24.693639090000158, RMSE: 4.969269472467775, R2 Score: 0.0031346063351004316\n"
     ]
    }
   ],
   "source": [
    "#Regresi Linier\n",
    "#Import library metode machine learning.\n",
    "import warnings\n",
    "import numpy as np #operasi numerik\n",
    "import pandas as pd #analisis data\n",
    "import matplotlib.pyplot as plt #visualisasi\n",
    "from sklearn.linear_model import LinearRegression #regresi linier\n",
    "from sklearn.model_selection import train_test_split #membagi data\n",
    "from sklearn.metrics import mean_squared_error, r2_score #menghitung metrik\n",
    "\n",
    "#Siapkan data yang akan ditraining fitur satu \"X_feature_dua\" dan output \n",
    "X_feature_dua = X[:,1:2]\n",
    "y_dua = y\n",
    "\n",
    "#split data training dan testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_feature_dua, y_dua, test_size=0.2, random_state=42) #test size 20% argument, dengan random state 42\n",
    "\n",
    "# Inisialisasi list untuk menyimpan hasil evaluasi kinerja setiap model\n",
    "mse_scores = [] #mean squared error\n",
    "rmse_scores = [] #root mean squared error\n",
    "r2_scores = [] #r-squared\n",
    "\n",
    "# Hyperparameter yang akan dieksplorasi\n",
    "learning_rates= [0.001, 0.01, 0.1]\n",
    "fit_intercepts = [True, False]\n",
    "\n",
    "#mencoba looping\n",
    "for lr in learning_rates:\n",
    "    for intercept in fit_intercepts:\n",
    "        model = LinearRegression(fit_intercept=intercept)\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "        rmse = np.sqrt(mse)\n",
    "        \n",
    "        try:\n",
    "            r2 = r2_score(y_test, y_pred)\n",
    "        except UndefinedMetricWarning as e: # type: ignore\n",
    "            msg = \"R^2 score is not well-defined with less than two samples.\"\n",
    "            warnings.warn(msg, UndefinedMetricWarning) # type: ignore\n",
    "            r2 = float(\"nan\")\n",
    "        \n",
    "        mse_scores.append(mse)\n",
    "        rmse_scores.append(rmse)\n",
    "        r2_scores.append(r2)\n",
    "        \n",
    "        print(f\"Learning Rate: {lr}, Fit Intercept: {intercept}\")\n",
    "        print(f\"MSE: {mse}, RMSE: {rmse}, R2 Score: {r2}\")\n",
    "        print(\"---------------------------------------------------\")\n",
    "\n",
    "#ukur kinerja setiap model pada setiap trainig dengan MSE,RMSE, R2.\n",
    "best_model_index = np.argmax(r2_scores)\n",
    "\n",
    "# Mendapatkan hyperparameter dari model terbaik\n",
    "best_lr_index = best_model_index // len(fit_intercepts)\n",
    "best_intercept_index = best_model_index % len(fit_intercepts)\n",
    "best_lr = learning_rates[best_lr_index]\n",
    "best_intercept = fit_intercepts[best_intercept_index]\n",
    "\n",
    "# Menampilkan model terbaik\n",
    "print(\"Model Terbaik:\")\n",
    "print(f\"Learning Rate: {best_lr}, Fit Intercept: {best_intercept}\")\n",
    "print(f\"MSE: {mse_scores[best_model_index]}, RMSE: {rmse_scores[best_model_index]}, R2 Score: {r2_scores[best_model_index]}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Orde: 2, Learning Rate: 0.001, Fit Intercept: True\n",
      "MSE: 24.85618397614367, RMSE: 4.985597654859813, R2 Score: -0.0034272200252469798\n",
      "---------------------------------------------------\n",
      "Orde: 2, Learning Rate: 0.001, Fit Intercept: False\n",
      "MSE: 24.856183976143665, RMSE: 4.985597654859813, R2 Score: -0.0034272200252467577\n",
      "---------------------------------------------------\n",
      "Orde: 2, Learning Rate: 0.01, Fit Intercept: True\n",
      "MSE: 24.85618397614367, RMSE: 4.985597654859813, R2 Score: -0.0034272200252469798\n",
      "---------------------------------------------------\n",
      "Orde: 2, Learning Rate: 0.01, Fit Intercept: False\n",
      "MSE: 24.856183976143665, RMSE: 4.985597654859813, R2 Score: -0.0034272200252467577\n",
      "---------------------------------------------------\n",
      "Orde: 2, Learning Rate: 0.1, Fit Intercept: True\n",
      "MSE: 24.85618397614367, RMSE: 4.985597654859813, R2 Score: -0.0034272200252469798\n",
      "---------------------------------------------------\n",
      "Orde: 2, Learning Rate: 0.1, Fit Intercept: False\n",
      "MSE: 24.856183976143665, RMSE: 4.985597654859813, R2 Score: -0.0034272200252467577\n",
      "---------------------------------------------------\n",
      "Orde: 3, Learning Rate: 0.001, Fit Intercept: True\n",
      "MSE: 24.852940995377285, RMSE: 4.985272409345079, R2 Score: -0.0032963031001818077\n",
      "---------------------------------------------------\n",
      "Orde: 3, Learning Rate: 0.001, Fit Intercept: False\n",
      "MSE: 24.852940995377285, RMSE: 4.985272409345079, R2 Score: -0.0032963031001818077\n",
      "---------------------------------------------------\n",
      "Orde: 3, Learning Rate: 0.01, Fit Intercept: True\n",
      "MSE: 24.852940995377285, RMSE: 4.985272409345079, R2 Score: -0.0032963031001818077\n",
      "---------------------------------------------------\n",
      "Orde: 3, Learning Rate: 0.01, Fit Intercept: False\n",
      "MSE: 24.852940995377285, RMSE: 4.985272409345079, R2 Score: -0.0032963031001818077\n",
      "---------------------------------------------------\n",
      "Orde: 3, Learning Rate: 0.1, Fit Intercept: True\n",
      "MSE: 24.852940995377285, RMSE: 4.985272409345079, R2 Score: -0.0032963031001818077\n",
      "---------------------------------------------------\n",
      "Orde: 3, Learning Rate: 0.1, Fit Intercept: False\n",
      "MSE: 24.852940995377285, RMSE: 4.985272409345079, R2 Score: -0.0032963031001818077\n",
      "---------------------------------------------------\n",
      "Orde: 4, Learning Rate: 0.001, Fit Intercept: True\n",
      "MSE: 24.886259394695394, RMSE: 4.988612973031221, R2 Score: -0.004641344190783325\n",
      "---------------------------------------------------\n",
      "Orde: 4, Learning Rate: 0.001, Fit Intercept: False\n",
      "MSE: 24.886259394695394, RMSE: 4.988612973031221, R2 Score: -0.004641344190783325\n",
      "---------------------------------------------------\n",
      "Orde: 4, Learning Rate: 0.01, Fit Intercept: True\n",
      "MSE: 24.886259394695394, RMSE: 4.988612973031221, R2 Score: -0.004641344190783325\n",
      "---------------------------------------------------\n",
      "Orde: 4, Learning Rate: 0.01, Fit Intercept: False\n",
      "MSE: 24.886259394695394, RMSE: 4.988612973031221, R2 Score: -0.004641344190783325\n",
      "---------------------------------------------------\n",
      "Orde: 4, Learning Rate: 0.1, Fit Intercept: True\n",
      "MSE: 24.886259394695394, RMSE: 4.988612973031221, R2 Score: -0.004641344190783325\n",
      "---------------------------------------------------\n",
      "Orde: 4, Learning Rate: 0.1, Fit Intercept: False\n",
      "MSE: 24.886259394695394, RMSE: 4.988612973031221, R2 Score: -0.004641344190783325\n",
      "---------------------------------------------------\n",
      "Orde: 5, Learning Rate: 0.001, Fit Intercept: True\n",
      "MSE: 24.449515346757863, RMSE: 4.944645118383913, R2 Score: 0.012989715601224305\n",
      "---------------------------------------------------\n",
      "Orde: 5, Learning Rate: 0.001, Fit Intercept: False\n",
      "MSE: 24.449515346757853, RMSE: 4.944645118383912, R2 Score: 0.012989715601224638\n",
      "---------------------------------------------------\n",
      "Orde: 5, Learning Rate: 0.01, Fit Intercept: True\n",
      "MSE: 24.449515346757863, RMSE: 4.944645118383913, R2 Score: 0.012989715601224305\n",
      "---------------------------------------------------\n",
      "Orde: 5, Learning Rate: 0.01, Fit Intercept: False\n",
      "MSE: 24.449515346757853, RMSE: 4.944645118383912, R2 Score: 0.012989715601224638\n",
      "---------------------------------------------------\n",
      "Orde: 5, Learning Rate: 0.1, Fit Intercept: True\n",
      "MSE: 24.449515346757863, RMSE: 4.944645118383913, R2 Score: 0.012989715601224305\n",
      "---------------------------------------------------\n",
      "Orde: 5, Learning Rate: 0.1, Fit Intercept: False\n",
      "MSE: 24.449515346757853, RMSE: 4.944645118383912, R2 Score: 0.012989715601224638\n",
      "---------------------------------------------------\n",
      "Orde: 6, Learning Rate: 0.001, Fit Intercept: True\n",
      "MSE: 24.638931197790093, RMSE: 4.96376179905826, R2 Score: 0.0053431266874792716\n",
      "---------------------------------------------------\n",
      "Orde: 6, Learning Rate: 0.001, Fit Intercept: False\n",
      "MSE: 24.638931197790072, RMSE: 4.963761799058258, R2 Score: 0.00534312668748016\n",
      "---------------------------------------------------\n",
      "Orde: 6, Learning Rate: 0.01, Fit Intercept: True\n",
      "MSE: 24.638931197790093, RMSE: 4.96376179905826, R2 Score: 0.0053431266874792716\n",
      "---------------------------------------------------\n",
      "Orde: 6, Learning Rate: 0.01, Fit Intercept: False\n",
      "MSE: 24.638931197790072, RMSE: 4.963761799058258, R2 Score: 0.00534312668748016\n",
      "---------------------------------------------------\n",
      "Orde: 6, Learning Rate: 0.1, Fit Intercept: True\n",
      "MSE: 24.638931197790093, RMSE: 4.96376179905826, R2 Score: 0.0053431266874792716\n",
      "---------------------------------------------------\n",
      "Orde: 6, Learning Rate: 0.1, Fit Intercept: False\n",
      "MSE: 24.638931197790072, RMSE: 4.963761799058258, R2 Score: 0.00534312668748016\n",
      "---------------------------------------------------\n",
      "Orde: 7, Learning Rate: 0.001, Fit Intercept: True\n",
      "MSE: 24.3765512934063, RMSE: 4.93726151762354, R2 Score: 0.015935224746417287\n",
      "---------------------------------------------------\n",
      "Orde: 7, Learning Rate: 0.001, Fit Intercept: False\n",
      "MSE: 24.376551293406308, RMSE: 4.937261517623541, R2 Score: 0.015935224746416954\n",
      "---------------------------------------------------\n",
      "Orde: 7, Learning Rate: 0.01, Fit Intercept: True\n",
      "MSE: 24.3765512934063, RMSE: 4.93726151762354, R2 Score: 0.015935224746417287\n",
      "---------------------------------------------------\n",
      "Orde: 7, Learning Rate: 0.01, Fit Intercept: False\n",
      "MSE: 24.376551293406308, RMSE: 4.937261517623541, R2 Score: 0.015935224746416954\n",
      "---------------------------------------------------\n",
      "Orde: 7, Learning Rate: 0.1, Fit Intercept: True\n",
      "MSE: 24.3765512934063, RMSE: 4.93726151762354, R2 Score: 0.015935224746417287\n",
      "---------------------------------------------------\n",
      "Orde: 7, Learning Rate: 0.1, Fit Intercept: False\n",
      "MSE: 24.376551293406308, RMSE: 4.937261517623541, R2 Score: 0.015935224746416954\n",
      "---------------------------------------------------\n",
      "Orde: 8, Learning Rate: 0.001, Fit Intercept: True\n",
      "MSE: 24.25738153578597, RMSE: 4.925178325277773, R2 Score: 0.02074602670679937\n",
      "---------------------------------------------------\n",
      "Orde: 8, Learning Rate: 0.001, Fit Intercept: False\n",
      "MSE: 24.257381535785935, RMSE: 4.92517832527777, R2 Score: 0.020746026706800813\n",
      "---------------------------------------------------\n",
      "Orde: 8, Learning Rate: 0.01, Fit Intercept: True\n",
      "MSE: 24.25738153578597, RMSE: 4.925178325277773, R2 Score: 0.02074602670679937\n",
      "---------------------------------------------------\n",
      "Orde: 8, Learning Rate: 0.01, Fit Intercept: False\n",
      "MSE: 24.257381535785935, RMSE: 4.92517832527777, R2 Score: 0.020746026706800813\n",
      "---------------------------------------------------\n",
      "Orde: 8, Learning Rate: 0.1, Fit Intercept: True\n",
      "MSE: 24.25738153578597, RMSE: 4.925178325277773, R2 Score: 0.02074602670679937\n",
      "---------------------------------------------------\n",
      "Orde: 8, Learning Rate: 0.1, Fit Intercept: False\n",
      "MSE: 24.257381535785935, RMSE: 4.92517832527777, R2 Score: 0.020746026706800813\n",
      "---------------------------------------------------\n",
      "Orde: 9, Learning Rate: 0.001, Fit Intercept: True\n",
      "MSE: 24.300764842698186, RMSE: 4.929580595009902, R2 Score: 0.018994672150838277\n",
      "---------------------------------------------------\n",
      "Orde: 9, Learning Rate: 0.001, Fit Intercept: False\n",
      "MSE: 24.30076484269773, RMSE: 4.929580595009856, R2 Score: 0.018994672150856706\n",
      "---------------------------------------------------\n",
      "Orde: 9, Learning Rate: 0.01, Fit Intercept: True\n",
      "MSE: 24.300764842698186, RMSE: 4.929580595009902, R2 Score: 0.018994672150838277\n",
      "---------------------------------------------------\n",
      "Orde: 9, Learning Rate: 0.01, Fit Intercept: False\n",
      "MSE: 24.30076484269773, RMSE: 4.929580595009856, R2 Score: 0.018994672150856706\n",
      "---------------------------------------------------\n",
      "Orde: 9, Learning Rate: 0.1, Fit Intercept: True\n",
      "MSE: 24.300764842698186, RMSE: 4.929580595009902, R2 Score: 0.018994672150838277\n",
      "---------------------------------------------------\n",
      "Orde: 9, Learning Rate: 0.1, Fit Intercept: False\n",
      "MSE: 24.30076484269773, RMSE: 4.929580595009856, R2 Score: 0.018994672150856706\n",
      "---------------------------------------------------\n",
      "Best Model:\n",
      "Orde: 8, Learning Rate: 0.001, Fit Intercept: False\n",
      "MSE: 24.257381535785935, RMSE: 4.92517832527777, R2 Score: 0.020746026706800813\n"
     ]
    }
   ],
   "source": [
    "#Regresi Polinomial\n",
    "#Import library metode machine learning.\n",
    "import warnings\n",
    "import numpy as np #operasi numerik\n",
    "import pandas as pd #analisis data\n",
    "import matplotlib.pyplot as plt #visualisasi\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.model_selection import train_test_split #membagi data\n",
    "from sklearn.metrics import mean_squared_error, r2_score #menghitung metrik\n",
    "\n",
    "#Siapkan data yang akan ditraining fitur satu \"X_feature_dua\" dan output \n",
    "X_feature_dua = X[:,1:2]\n",
    "y_dua = y\n",
    "\n",
    "#split data training dan testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_feature_dua, y_dua, test_size=0.2, random_state=42) #test size 20% argument, dengan random state 42\n",
    "\n",
    "# Inisialisasi list untuk evaluasi metrik\n",
    "best_model_index = None\n",
    "best_mse = np.inf\n",
    "best_rmse = np.inf\n",
    "best_r2 = -np.inf\n",
    "\n",
    "# Hyperparameter yang akan dieksplorasi\n",
    "ordes = range(2,10) #experiment\n",
    "learning_rates= [0.001, 0.01, 0.1] #experiment\n",
    "fit_intercepts = [True, False]\n",
    "\n",
    "#mencoba looping\n",
    "for order in ordes:\n",
    "    for lr in learning_rates:\n",
    "        for fit_intercept in fit_intercepts:\n",
    "            # membuat polynomial features transformer\n",
    "            poly = PolynomialFeatures(degree=order)\n",
    "\n",
    "            # Transform features (membuat polynomial terms)\n",
    "            X_train_poly = poly.fit_transform(X_train.reshape(-1, 1))\n",
    "            X_test_poly = poly.transform(X_test.reshape(-1, 1))\n",
    "\n",
    "            # membuat linear regression model\n",
    "            model = LinearRegression(fit_intercept=fit_intercept)\n",
    "            model.fit(X_train_poly, y_train)\n",
    "\n",
    "            # Prediksi\n",
    "            y_pred = model.predict(X_test_poly)\n",
    "\n",
    "            # Evaluasi\n",
    "            mse = mean_squared_error(y_test, y_pred)\n",
    "            rmse = np.sqrt(mse)\n",
    "            r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "            # Hasil\n",
    "            print(f\"Orde: {order}, Learning Rate: {lr}, Fit Intercept: {fit_intercept}\")\n",
    "            print(f\"MSE: {mse}, RMSE: {rmse}, R2 Score: {r2}\")\n",
    "            print(\"---------------------------------------------------\")\n",
    "\n",
    "            # Update model terbaik berdasarkan R2\n",
    "            if r2 > best_r2:\n",
    "                best_model_index = (order, lr, fit_intercept)\n",
    "                best_mse = mse\n",
    "                best_rmse = rmse\n",
    "                best_r2 = r2\n",
    "\n",
    "# Detail hasil dari model terbaik\n",
    "print(\"Best Model:\")\n",
    "print(f\"Orde: {best_model_index[0]}, Learning Rate: {best_model_index[1]}, Fit Intercept: {best_model_index[2]}\")\n",
    "print(f\"MSE: {best_mse}, RMSE: {best_rmse}, R2 Score: {best_r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Depth: 3, Criterion: squared_error\n",
      "MSE: 24.205865892797746, RMSE: 4.919945720513362, R2 Score: 0.02282567813201819\n",
      "---------------------------------------------------\n",
      "Max Depth: 3, Criterion: friedman_mse\n",
      "MSE: 24.205865892797746, RMSE: 4.919945720513362, R2 Score: 0.02282567813201819\n",
      "---------------------------------------------------\n",
      "Max Depth: 3, Criterion: absolute_error\n",
      "MSE: 25.851285491352293, RMSE: 5.084415943975502, R2 Score: -0.043598790528870834\n",
      "---------------------------------------------------\n",
      "Max Depth: 4, Criterion: squared_error\n",
      "MSE: 24.35344824287633, RMSE: 4.934921300575758, R2 Score: 0.016867879163106614\n",
      "---------------------------------------------------\n",
      "Max Depth: 4, Criterion: friedman_mse\n",
      "MSE: 24.35344824287633, RMSE: 4.934921300575758, R2 Score: 0.016867879163106614\n",
      "---------------------------------------------------\n",
      "Max Depth: 4, Criterion: absolute_error\n",
      "MSE: 26.096697222962586, RMSE: 5.10849265664174, R2 Score: -0.05350589500828895\n",
      "---------------------------------------------------\n",
      "Max Depth: 5, Criterion: squared_error\n",
      "MSE: 24.395259149416116, RMSE: 4.939155712205895, R2 Score: 0.015180001339373916\n",
      "---------------------------------------------------\n",
      "Max Depth: 5, Criterion: friedman_mse\n",
      "MSE: 24.395259149416116, RMSE: 4.939155712205895, R2 Score: 0.015180001339373916\n",
      "---------------------------------------------------\n",
      "Max Depth: 5, Criterion: absolute_error\n",
      "MSE: 26.708693777404097, RMSE: 5.168045450400383, R2 Score: -0.0782117791406911\n",
      "---------------------------------------------------\n",
      "Max Depth: 6, Criterion: squared_error\n",
      "MSE: 24.18842761639402, RMSE: 4.918173199104929, R2 Score: 0.023529649474949066\n",
      "---------------------------------------------------\n",
      "Max Depth: 6, Criterion: friedman_mse\n",
      "MSE: 24.18842761639402, RMSE: 4.918173199104929, R2 Score: 0.023529649474949066\n",
      "---------------------------------------------------\n",
      "Max Depth: 6, Criterion: absolute_error\n",
      "MSE: 26.640032126444357, RMSE: 5.161398272410719, R2 Score: -0.0754399550501148\n",
      "---------------------------------------------------\n",
      "Max Depth: 7, Criterion: squared_error\n",
      "MSE: 26.396109230384305, RMSE: 5.137714397510269, R2 Score: -0.06559295384796071\n",
      "---------------------------------------------------\n",
      "Max Depth: 7, Criterion: friedman_mse\n",
      "MSE: 26.396109230384305, RMSE: 5.137714397510269, R2 Score: -0.06559295384796071\n",
      "---------------------------------------------------\n",
      "Max Depth: 7, Criterion: absolute_error\n",
      "MSE: 26.985068694385017, RMSE: 5.194715458462092, R2 Score: -0.0893688463275546\n",
      "---------------------------------------------------\n",
      "Max Depth: 8, Criterion: squared_error\n",
      "MSE: 25.714363813826363, RMSE: 5.070933229083811, R2 Score: -0.038071355650978855\n",
      "---------------------------------------------------\n",
      "Max Depth: 8, Criterion: friedman_mse\n",
      "MSE: 25.714363813826363, RMSE: 5.070933229083811, R2 Score: -0.038071355650978855\n",
      "---------------------------------------------------\n",
      "Max Depth: 8, Criterion: absolute_error\n",
      "MSE: 27.237320960257275, RMSE: 5.218938681404225, R2 Score: -0.0995520985167162\n",
      "---------------------------------------------------\n",
      "Max Depth: 9, Criterion: squared_error\n",
      "MSE: 25.852184789385845, RMSE: 5.084504379916084, R2 Score: -0.04363509457806236\n",
      "---------------------------------------------------\n",
      "Max Depth: 9, Criterion: friedman_mse\n",
      "MSE: 25.852184789385845, RMSE: 5.084504379916084, R2 Score: -0.04363509457806236\n",
      "---------------------------------------------------\n",
      "Max Depth: 9, Criterion: absolute_error\n",
      "MSE: 26.5606323958196, RMSE: 5.153700844618322, R2 Score: -0.07223464199610685\n",
      "---------------------------------------------------\n",
      "Max Depth: 10, Criterion: squared_error\n",
      "MSE: 26.069954955370466, RMSE: 5.105874553430633, R2 Score: -0.05242632787711221\n",
      "---------------------------------------------------\n",
      "Max Depth: 10, Criterion: friedman_mse\n",
      "MSE: 26.069954955370466, RMSE: 5.105874553430633, R2 Score: -0.05242632787711221\n",
      "---------------------------------------------------\n",
      "Max Depth: 10, Criterion: absolute_error\n",
      "MSE: 26.1413295304666, RMSE: 5.1128592324125846, R2 Score: -0.05530767086757016\n",
      "---------------------------------------------------\n",
      "Max Depth: 11, Criterion: squared_error\n",
      "MSE: 26.9077237479485, RMSE: 5.187265536672332, R2 Score: -0.08624648351191544\n",
      "---------------------------------------------------\n",
      "Max Depth: 11, Criterion: friedman_mse\n",
      "MSE: 26.9077237479485, RMSE: 5.187265536672332, R2 Score: -0.08624648351191544\n",
      "---------------------------------------------------\n",
      "Max Depth: 11, Criterion: absolute_error\n",
      "MSE: 25.579162547089087, RMSE: 5.057584655454527, R2 Score: -0.03261337258502284\n",
      "---------------------------------------------------\n",
      "Max Depth: 12, Criterion: squared_error\n",
      "MSE: 27.856067453734678, RMSE: 5.2778847518427945, R2 Score: -0.12453047309128062\n",
      "---------------------------------------------------\n",
      "Max Depth: 12, Criterion: friedman_mse\n",
      "MSE: 27.856067453734678, RMSE: 5.2778847518427945, R2 Score: -0.12453047309128062\n",
      "---------------------------------------------------\n",
      "Max Depth: 12, Criterion: absolute_error\n",
      "MSE: 25.413746599030073, RMSE: 5.041204875724659, R2 Score: -0.025935643410343268\n",
      "---------------------------------------------------\n",
      "Max Depth: 13, Criterion: squared_error\n",
      "MSE: 28.610960940498135, RMSE: 5.348921474512235, R2 Score: -0.15500500906853398\n",
      "---------------------------------------------------\n",
      "Max Depth: 13, Criterion: friedman_mse\n",
      "MSE: 28.610960940498135, RMSE: 5.348921474512235, R2 Score: -0.15500500906853398\n",
      "---------------------------------------------------\n",
      "Max Depth: 13, Criterion: absolute_error\n",
      "MSE: 25.84301005551266, RMSE: 5.08360207485919, R2 Score: -0.04326471681960675\n",
      "---------------------------------------------------\n",
      "Max Depth: 14, Criterion: squared_error\n",
      "MSE: 28.461984111212395, RMSE: 5.334977423683478, R2 Score: -0.14899091592367153\n",
      "---------------------------------------------------\n",
      "Max Depth: 14, Criterion: friedman_mse\n",
      "MSE: 28.461984111212395, RMSE: 5.334977423683478, R2 Score: -0.14899091592367153\n",
      "---------------------------------------------------\n",
      "Max Depth: 14, Criterion: absolute_error\n",
      "MSE: 25.64088268345922, RMSE: 5.0636827194700125, R2 Score: -0.035104972458796846\n",
      "---------------------------------------------------\n",
      "Max Depth: 15, Criterion: squared_error\n",
      "MSE: 29.032785427690524, RMSE: 5.3882079978124935, R2 Score: -0.17203377635349937\n",
      "---------------------------------------------------\n",
      "Max Depth: 15, Criterion: friedman_mse\n",
      "MSE: 29.032785427690524, RMSE: 5.3882079978124935, R2 Score: -0.17203377635349937\n",
      "---------------------------------------------------\n",
      "Max Depth: 15, Criterion: absolute_error\n",
      "MSE: 27.181747758453163, RMSE: 5.21361177672956, R2 Score: -0.09730864620530255\n",
      "---------------------------------------------------\n",
      "Max Depth: 16, Criterion: squared_error\n",
      "MSE: 30.244410388863326, RMSE: 5.499491830056967, R2 Score: -0.2209462509179656\n",
      "---------------------------------------------------\n",
      "Max Depth: 16, Criterion: friedman_mse\n",
      "MSE: 30.244410388863326, RMSE: 5.499491830056967, R2 Score: -0.2209462509179656\n",
      "---------------------------------------------------\n",
      "Max Depth: 16, Criterion: absolute_error\n",
      "MSE: 28.49425413393945, RMSE: 5.338000949226166, R2 Score: -0.15029363476523772\n",
      "---------------------------------------------------\n",
      "Max Depth: 17, Criterion: squared_error\n",
      "MSE: 30.07448967085536, RMSE: 5.484021304741199, R2 Score: -0.2140866672482007\n",
      "---------------------------------------------------\n",
      "Max Depth: 17, Criterion: friedman_mse\n",
      "MSE: 30.07448967085536, RMSE: 5.484021304741199, R2 Score: -0.2140866672482007\n",
      "---------------------------------------------------\n",
      "Max Depth: 17, Criterion: absolute_error\n",
      "MSE: 28.911422465158644, RMSE: 5.376934299873734, R2 Score: -0.16713443620441315\n",
      "---------------------------------------------------\n",
      "Max Depth: 18, Criterion: squared_error\n",
      "MSE: 30.061750530450126, RMSE: 5.48285970369935, R2 Score: -0.21357239682541174\n",
      "---------------------------------------------------\n",
      "Max Depth: 18, Criterion: friedman_mse\n",
      "MSE: 30.061750530450126, RMSE: 5.48285970369935, R2 Score: -0.21357239682541174\n",
      "---------------------------------------------------\n",
      "Max Depth: 18, Criterion: absolute_error\n",
      "MSE: 33.102999349911684, RMSE: 5.753520604804652, R2 Score: -0.336345540572911\n",
      "---------------------------------------------------\n",
      "Max Depth: 19, Criterion: squared_error\n",
      "MSE: 29.407880216820477, RMSE: 5.42290330144476, R2 Score: -0.18717609755066555\n",
      "---------------------------------------------------\n",
      "Max Depth: 19, Criterion: friedman_mse\n",
      "MSE: 29.407880216820477, RMSE: 5.42290330144476, R2 Score: -0.18717609755066555\n",
      "---------------------------------------------------\n",
      "Max Depth: 19, Criterion: absolute_error\n",
      "MSE: 33.14975423980159, RMSE: 5.757582325924797, R2 Score: -0.3382330036376291\n",
      "---------------------------------------------------\n",
      "Best Model:\n",
      "Max Depth: 6, Criterion: squared_error\n",
      "MSE: 24.18842761639402, RMSE: 4.918173199104929, R2 Score: 0.023529649474949066\n"
     ]
    }
   ],
   "source": [
    "#Decission Tree Regression\n",
    "#Import library metode machine learning.\n",
    "import warnings\n",
    "import numpy as np #operasi numerik\n",
    "import pandas as pd #analisis data\n",
    "import matplotlib.pyplot as plt #visualisasi\n",
    "from sklearn.tree import DecisionTreeRegressor #Decisiion Tree\n",
    "from sklearn.model_selection import train_test_split #membagi data\n",
    "from sklearn.metrics import mean_squared_error, r2_score #menghitung metrik\n",
    "\n",
    "#Siapkan data yang akan ditraining fitur satu \"X_feature_dua\" dan output \n",
    "X_feature_dua = X[:,1:2]\n",
    "y_dua = y\n",
    "\n",
    "#split data training dan testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_feature_dua, y_dua, test_size=0.2, random_state=42) #test size 20% argument, dengan random state 42\n",
    "\n",
    "# Inisialisasi list untuk evaluasi metrik\n",
    "best_model_index = None\n",
    "best_mse = np.inf\n",
    "best_rmse = np.inf\n",
    "best_r2 = -np.inf\n",
    "\n",
    "# Hyperparameter yang akan dieksplorasi\n",
    "max_depths = range(3,20) #experiment\n",
    "criterions = ['squared_error', 'friedman_mse', 'absolute_error'] #experiment criteria\n",
    "\n",
    "#mencoba looping\n",
    "for max_depth in max_depths:\n",
    "    for criterion in criterions:\n",
    "        # membuat model decision tree regression\n",
    "        model = DecisionTreeRegressor(max_depth=max_depth, criterion=criterion)\n",
    "\n",
    "        # melatih model\n",
    "        model.fit(X_train.reshape(-1, 1), y_train)\n",
    "\n",
    "        # Prediksi\n",
    "        y_pred = model.predict(X_test.reshape(-1, 1))\n",
    "\n",
    "        # Evaluasi\n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "        rmse = np.sqrt(mse)\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "        # Hasil\n",
    "        print(f\"Max Depth: {max_depth}, Criterion: {criterion}\")\n",
    "        print(f\"MSE: {mse}, RMSE: {rmse}, R2 Score: {r2}\")\n",
    "        print(\"---------------------------------------------------\")\n",
    "\n",
    "        # Update model terbaik berdsarkan R2\n",
    "        if r2 > best_r2:\n",
    "            best_model_index = (max_depth, criterion)\n",
    "            best_mse = mse\n",
    "            best_rmse = rmse\n",
    "            best_r2 = r2\n",
    "\n",
    "# Detail hasil dari model terbaik\n",
    "print(\"Best Model:\")\n",
    "print(f\"Max Depth: {best_model_index[0]}, Criterion: {best_model_index[1]}\")\n",
    "print(f\"MSE: {best_mse}, RMSE: {best_rmse}, R2 Score: {best_r2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q2. process training dengan **fitur 3 dan output** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_feature_ketiga = X[:,2:3] #ambil kolom ketiga"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning Rate: 0.001, Fit Intercept: True\n",
      "MSE: 24.892958875631383, RMSE: 4.989284405165874, R2 Score: -0.004911797673814444\n",
      "---------------------------------------------------\n",
      "Learning Rate: 0.001, Fit Intercept: False\n",
      "MSE: 24.845164033965435, RMSE: 4.984492354690238, R2 Score: -0.0029823524641057197\n",
      "---------------------------------------------------\n",
      "Learning Rate: 0.01, Fit Intercept: True\n",
      "MSE: 24.892958875631383, RMSE: 4.989284405165874, R2 Score: -0.004911797673814444\n",
      "---------------------------------------------------\n",
      "Learning Rate: 0.01, Fit Intercept: False\n",
      "MSE: 24.845164033965435, RMSE: 4.984492354690238, R2 Score: -0.0029823524641057197\n",
      "---------------------------------------------------\n",
      "Learning Rate: 0.1, Fit Intercept: True\n",
      "MSE: 24.892958875631383, RMSE: 4.989284405165874, R2 Score: -0.004911797673814444\n",
      "---------------------------------------------------\n",
      "Learning Rate: 0.1, Fit Intercept: False\n",
      "MSE: 24.845164033965435, RMSE: 4.984492354690238, R2 Score: -0.0029823524641057197\n",
      "---------------------------------------------------\n",
      "Model Terbaik:\n",
      "Learning Rate: 0.001, Fit Intercept: False\n",
      "MSE: 24.845164033965435, RMSE: 4.984492354690238, R2 Score: -0.0029823524641057197\n"
     ]
    }
   ],
   "source": [
    "#Regresi Linier\n",
    "#Import library metode machine learning.\n",
    "import warnings\n",
    "import numpy as np #operasi numerik\n",
    "import pandas as pd #analisis data\n",
    "import matplotlib.pyplot as plt #visualisasi\n",
    "from sklearn.linear_model import LinearRegression #regresi linier\n",
    "from sklearn.model_selection import train_test_split #membagi data\n",
    "from sklearn.metrics import mean_squared_error, r2_score #menghitung metrik\n",
    "\n",
    "#Siapkan data yang akan ditraining fitur satu \"X_feature_tiga\" dan output \n",
    "X_feature_ketiga = X[:,2:3]\n",
    "y_tiga = y\n",
    "\n",
    "#split data training dan testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_feature_ketiga, y_tiga, test_size=0.2, random_state=42) #test size 20% argument, dengan random state 42\n",
    "\n",
    "# Inisialisasi list untuk menyimpan hasil evaluasi kinerja setiap model\n",
    "mse_scores = [] #mean squared error\n",
    "rmse_scores = [] #root mean squared error\n",
    "r2_scores = [] #r-squared\n",
    "\n",
    "# Hyperparameter yang akan dieksplorasi\n",
    "learning_rates= [0.001, 0.01, 0.1]\n",
    "fit_intercepts = [True, False]\n",
    "\n",
    "#mencoba looping\n",
    "for lr in learning_rates:\n",
    "    for intercept in fit_intercepts:\n",
    "        model = LinearRegression(fit_intercept=intercept)\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "        rmse = np.sqrt(mse)\n",
    "        \n",
    "        try:\n",
    "            r2 = r2_score(y_test, y_pred)\n",
    "        except UndefinedMetricWarning as e: # type: ignore\n",
    "            msg = \"R^2 score is not well-defined with less than two samples.\"\n",
    "            warnings.warn(msg, UndefinedMetricWarning) # type: ignore\n",
    "            r2 = float(\"nan\")\n",
    "        \n",
    "        mse_scores.append(mse)\n",
    "        rmse_scores.append(rmse)\n",
    "        r2_scores.append(r2)\n",
    "        \n",
    "        print(f\"Learning Rate: {lr}, Fit Intercept: {intercept}\")\n",
    "        print(f\"MSE: {mse}, RMSE: {rmse}, R2 Score: {r2}\")\n",
    "        print(\"---------------------------------------------------\")\n",
    "\n",
    "#ukur kinerja setiap model pada setiap trainig dengan MSE,RMSE, R2.\n",
    "best_model_index = np.argmax(r2_scores)\n",
    "\n",
    "# Mendapatkan hyperparameter dari model terbaik\n",
    "best_lr_index = best_model_index // len(fit_intercepts)\n",
    "best_intercept_index = best_model_index % len(fit_intercepts)\n",
    "best_lr = learning_rates[best_lr_index]\n",
    "best_intercept = fit_intercepts[best_intercept_index]\n",
    "\n",
    "# Menampilkan model terbaik\n",
    "print(\"Model Terbaik:\")\n",
    "print(f\"Learning Rate: {best_lr}, Fit Intercept: {best_intercept}\")\n",
    "print(f\"MSE: {mse_scores[best_model_index]}, RMSE: {rmse_scores[best_model_index]}, R2 Score: {r2_scores[best_model_index]}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Orde: 2, Learning Rate: 0.001, Fit Intercept: True\n",
      "MSE: 25.370017124972, RMSE: 5.036865803748597, R2 Score: -0.02417031432244432\n",
      "---------------------------------------------------\n",
      "Orde: 2, Learning Rate: 0.001, Fit Intercept: False\n",
      "MSE: 25.370017124972, RMSE: 5.036865803748597, R2 Score: -0.02417031432244432\n",
      "---------------------------------------------------\n",
      "Orde: 2, Learning Rate: 0.01, Fit Intercept: True\n",
      "MSE: 25.370017124972, RMSE: 5.036865803748597, R2 Score: -0.02417031432244432\n",
      "---------------------------------------------------\n",
      "Orde: 2, Learning Rate: 0.01, Fit Intercept: False\n",
      "MSE: 25.370017124972, RMSE: 5.036865803748597, R2 Score: -0.02417031432244432\n",
      "---------------------------------------------------\n",
      "Orde: 2, Learning Rate: 0.1, Fit Intercept: True\n",
      "MSE: 25.370017124972, RMSE: 5.036865803748597, R2 Score: -0.02417031432244432\n",
      "---------------------------------------------------\n",
      "Orde: 2, Learning Rate: 0.1, Fit Intercept: False\n",
      "MSE: 25.370017124972, RMSE: 5.036865803748597, R2 Score: -0.02417031432244432\n",
      "---------------------------------------------------\n",
      "Orde: 3, Learning Rate: 0.001, Fit Intercept: True\n",
      "MSE: 25.352288587975085, RMSE: 5.03510561835351, R2 Score: -0.023454625357034242\n",
      "---------------------------------------------------\n",
      "Orde: 3, Learning Rate: 0.001, Fit Intercept: False\n",
      "MSE: 25.352288587975096, RMSE: 5.035105618353511, R2 Score: -0.023454625357034464\n",
      "---------------------------------------------------\n",
      "Orde: 3, Learning Rate: 0.01, Fit Intercept: True\n",
      "MSE: 25.352288587975085, RMSE: 5.03510561835351, R2 Score: -0.023454625357034242\n",
      "---------------------------------------------------\n",
      "Orde: 3, Learning Rate: 0.01, Fit Intercept: False\n",
      "MSE: 25.352288587975096, RMSE: 5.035105618353511, R2 Score: -0.023454625357034464\n",
      "---------------------------------------------------\n",
      "Orde: 3, Learning Rate: 0.1, Fit Intercept: True\n",
      "MSE: 25.352288587975085, RMSE: 5.03510561835351, R2 Score: -0.023454625357034242\n",
      "---------------------------------------------------\n",
      "Orde: 3, Learning Rate: 0.1, Fit Intercept: False\n",
      "MSE: 25.352288587975096, RMSE: 5.035105618353511, R2 Score: -0.023454625357034464\n",
      "---------------------------------------------------\n",
      "Orde: 4, Learning Rate: 0.001, Fit Intercept: True\n",
      "MSE: 25.379704867906195, RMSE: 5.037827395604795, R2 Score: -0.024561401907332803\n",
      "---------------------------------------------------\n",
      "Orde: 4, Learning Rate: 0.001, Fit Intercept: False\n",
      "MSE: 25.379704867906195, RMSE: 5.037827395604795, R2 Score: -0.024561401907332803\n",
      "---------------------------------------------------\n",
      "Orde: 4, Learning Rate: 0.01, Fit Intercept: True\n",
      "MSE: 25.379704867906195, RMSE: 5.037827395604795, R2 Score: -0.024561401907332803\n",
      "---------------------------------------------------\n",
      "Orde: 4, Learning Rate: 0.01, Fit Intercept: False\n",
      "MSE: 25.379704867906195, RMSE: 5.037827395604795, R2 Score: -0.024561401907332803\n",
      "---------------------------------------------------\n",
      "Orde: 4, Learning Rate: 0.1, Fit Intercept: True\n",
      "MSE: 25.379704867906195, RMSE: 5.037827395604795, R2 Score: -0.024561401907332803\n",
      "---------------------------------------------------\n",
      "Orde: 4, Learning Rate: 0.1, Fit Intercept: False\n",
      "MSE: 25.379704867906195, RMSE: 5.037827395604795, R2 Score: -0.024561401907332803\n",
      "---------------------------------------------------\n",
      "Orde: 5, Learning Rate: 0.001, Fit Intercept: True\n",
      "MSE: 25.5730787573738, RMSE: 5.056983167598425, R2 Score: -0.03236777413728498\n",
      "---------------------------------------------------\n",
      "Orde: 5, Learning Rate: 0.001, Fit Intercept: False\n",
      "MSE: 25.5730787573738, RMSE: 5.056983167598425, R2 Score: -0.03236777413728498\n",
      "---------------------------------------------------\n",
      "Orde: 5, Learning Rate: 0.01, Fit Intercept: True\n",
      "MSE: 25.5730787573738, RMSE: 5.056983167598425, R2 Score: -0.03236777413728498\n",
      "---------------------------------------------------\n",
      "Orde: 5, Learning Rate: 0.01, Fit Intercept: False\n",
      "MSE: 25.5730787573738, RMSE: 5.056983167598425, R2 Score: -0.03236777413728498\n",
      "---------------------------------------------------\n",
      "Orde: 5, Learning Rate: 0.1, Fit Intercept: True\n",
      "MSE: 25.5730787573738, RMSE: 5.056983167598425, R2 Score: -0.03236777413728498\n",
      "---------------------------------------------------\n",
      "Orde: 5, Learning Rate: 0.1, Fit Intercept: False\n",
      "MSE: 25.5730787573738, RMSE: 5.056983167598425, R2 Score: -0.03236777413728498\n",
      "---------------------------------------------------\n",
      "Orde: 6, Learning Rate: 0.001, Fit Intercept: True\n",
      "MSE: 25.070327700508525, RMSE: 5.007027831009982, R2 Score: -0.012072056345718174\n",
      "---------------------------------------------------\n",
      "Orde: 6, Learning Rate: 0.001, Fit Intercept: False\n",
      "MSE: 25.07032770050854, RMSE: 5.007027831009983, R2 Score: -0.012072056345718618\n",
      "---------------------------------------------------\n",
      "Orde: 6, Learning Rate: 0.01, Fit Intercept: True\n",
      "MSE: 25.070327700508525, RMSE: 5.007027831009982, R2 Score: -0.012072056345718174\n",
      "---------------------------------------------------\n",
      "Orde: 6, Learning Rate: 0.01, Fit Intercept: False\n",
      "MSE: 25.07032770050854, RMSE: 5.007027831009983, R2 Score: -0.012072056345718618\n",
      "---------------------------------------------------\n",
      "Orde: 6, Learning Rate: 0.1, Fit Intercept: True\n",
      "MSE: 25.070327700508525, RMSE: 5.007027831009982, R2 Score: -0.012072056345718174\n",
      "---------------------------------------------------\n",
      "Orde: 6, Learning Rate: 0.1, Fit Intercept: False\n",
      "MSE: 25.07032770050854, RMSE: 5.007027831009983, R2 Score: -0.012072056345718618\n",
      "---------------------------------------------------\n",
      "Orde: 7, Learning Rate: 0.001, Fit Intercept: True\n",
      "MSE: 25.389813357360772, RMSE: 5.0388305545394925, R2 Score: -0.024969474742720488\n",
      "---------------------------------------------------\n",
      "Orde: 7, Learning Rate: 0.001, Fit Intercept: False\n",
      "MSE: 25.38981335736075, RMSE: 5.038830554539491, R2 Score: -0.0249694747427196\n",
      "---------------------------------------------------\n",
      "Orde: 7, Learning Rate: 0.01, Fit Intercept: True\n",
      "MSE: 25.389813357360772, RMSE: 5.0388305545394925, R2 Score: -0.024969474742720488\n",
      "---------------------------------------------------\n",
      "Orde: 7, Learning Rate: 0.01, Fit Intercept: False\n",
      "MSE: 25.38981335736075, RMSE: 5.038830554539491, R2 Score: -0.0249694747427196\n",
      "---------------------------------------------------\n",
      "Orde: 7, Learning Rate: 0.1, Fit Intercept: True\n",
      "MSE: 25.389813357360772, RMSE: 5.0388305545394925, R2 Score: -0.024969474742720488\n",
      "---------------------------------------------------\n",
      "Orde: 7, Learning Rate: 0.1, Fit Intercept: False\n",
      "MSE: 25.38981335736075, RMSE: 5.038830554539491, R2 Score: -0.0249694747427196\n",
      "---------------------------------------------------\n",
      "Orde: 8, Learning Rate: 0.001, Fit Intercept: True\n",
      "MSE: 24.954799594298198, RMSE: 4.995477914504097, R2 Score: -0.007408265372788714\n",
      "---------------------------------------------------\n",
      "Orde: 8, Learning Rate: 0.001, Fit Intercept: False\n",
      "MSE: 24.954799594298198, RMSE: 4.995477914504097, R2 Score: -0.007408265372788714\n",
      "---------------------------------------------------\n",
      "Orde: 8, Learning Rate: 0.01, Fit Intercept: True\n",
      "MSE: 24.954799594298198, RMSE: 4.995477914504097, R2 Score: -0.007408265372788714\n",
      "---------------------------------------------------\n",
      "Orde: 8, Learning Rate: 0.01, Fit Intercept: False\n",
      "MSE: 24.954799594298198, RMSE: 4.995477914504097, R2 Score: -0.007408265372788714\n",
      "---------------------------------------------------\n",
      "Orde: 8, Learning Rate: 0.1, Fit Intercept: True\n",
      "MSE: 24.954799594298198, RMSE: 4.995477914504097, R2 Score: -0.007408265372788714\n",
      "---------------------------------------------------\n",
      "Orde: 8, Learning Rate: 0.1, Fit Intercept: False\n",
      "MSE: 24.954799594298198, RMSE: 4.995477914504097, R2 Score: -0.007408265372788714\n",
      "---------------------------------------------------\n",
      "Orde: 9, Learning Rate: 0.001, Fit Intercept: True\n",
      "MSE: 25.035457312855513, RMSE: 5.00354447495528, R2 Score: -0.010664362542942785\n",
      "---------------------------------------------------\n",
      "Orde: 9, Learning Rate: 0.001, Fit Intercept: False\n",
      "MSE: 25.035457312855325, RMSE: 5.003544474955262, R2 Score: -0.010664362542935013\n",
      "---------------------------------------------------\n",
      "Orde: 9, Learning Rate: 0.01, Fit Intercept: True\n",
      "MSE: 25.035457312855513, RMSE: 5.00354447495528, R2 Score: -0.010664362542942785\n",
      "---------------------------------------------------\n",
      "Orde: 9, Learning Rate: 0.01, Fit Intercept: False\n",
      "MSE: 25.035457312855325, RMSE: 5.003544474955262, R2 Score: -0.010664362542935013\n",
      "---------------------------------------------------\n",
      "Orde: 9, Learning Rate: 0.1, Fit Intercept: True\n",
      "MSE: 25.035457312855513, RMSE: 5.00354447495528, R2 Score: -0.010664362542942785\n",
      "---------------------------------------------------\n",
      "Orde: 9, Learning Rate: 0.1, Fit Intercept: False\n",
      "MSE: 25.035457312855325, RMSE: 5.003544474955262, R2 Score: -0.010664362542935013\n",
      "---------------------------------------------------\n",
      "Best Model:\n",
      "Orde: 8, Learning Rate: 0.001, Fit Intercept: True\n",
      "MSE: 24.954799594298198, RMSE: 4.995477914504097, R2 Score: -0.007408265372788714\n"
     ]
    }
   ],
   "source": [
    "#Regresi Polinomial\n",
    "#Import library metode machine learning.\n",
    "import warnings\n",
    "import numpy as np #operasi numerik\n",
    "import pandas as pd #analisis data\n",
    "import matplotlib.pyplot as plt #visualisasi\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.model_selection import train_test_split #membagi data\n",
    "from sklearn.metrics import mean_squared_error, r2_score #menghitung metrik\n",
    "\n",
    "#Siapkan data yang akan ditraining fitur satu \"X_feature_tiga\" dan output \n",
    "X_feature_ketiga = X[:,2:3]\n",
    "y_tiga = y\n",
    "\n",
    "#split data training dan testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_feature_ketiga, y_tiga, test_size=0.2, random_state=42) #test size 20% argument, dengan random state 42\n",
    "\n",
    "# Inisialisasi list untuk evaluasi metrik\n",
    "best_model_index = None\n",
    "best_mse = np.inf\n",
    "best_rmse = np.inf\n",
    "best_r2 = -np.inf\n",
    "\n",
    "# Hyperparameter yang akan dieksplorasi\n",
    "ordes = range(2,10) #experiment\n",
    "learning_rates= [0.001, 0.01, 0.1] #experiment\n",
    "fit_intercepts = [True, False]\n",
    "\n",
    "#mencoba looping\n",
    "for order in ordes:\n",
    "    for lr in learning_rates:\n",
    "        for fit_intercept in fit_intercepts:\n",
    "            # Membuat polynomial features transformer\n",
    "            poly = PolynomialFeatures(degree=order)\n",
    "\n",
    "            # Transform features (membuat polynomial terms)\n",
    "            X_train_poly = poly.fit_transform(X_train.reshape(-1, 1))\n",
    "            X_test_poly = poly.transform(X_test.reshape(-1, 1))\n",
    "\n",
    "            # membuat model linear regression\n",
    "            model = LinearRegression(fit_intercept=fit_intercept)\n",
    "            model.fit(X_train_poly, y_train)\n",
    "\n",
    "            # Prediksi\n",
    "            y_pred = model.predict(X_test_poly)\n",
    "\n",
    "            # Evaluasi\n",
    "            mse = mean_squared_error(y_test, y_pred)\n",
    "            rmse = np.sqrt(mse)\n",
    "            r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "            # Hasil\n",
    "            print(f\"Orde: {order}, Learning Rate: {lr}, Fit Intercept: {fit_intercept}\")\n",
    "            print(f\"MSE: {mse}, RMSE: {rmse}, R2 Score: {r2}\")\n",
    "            print(\"---------------------------------------------------\")\n",
    "\n",
    "            # Update model terbaik berdasarkan R2\n",
    "            if r2 > best_r2:\n",
    "                best_model_index = (order, lr, fit_intercept)\n",
    "                best_mse = mse\n",
    "                best_rmse = rmse\n",
    "                best_r2 = r2\n",
    "\n",
    "# Detail hasil dari model terbaik\n",
    "print(\"Best Model:\")\n",
    "print(f\"Orde: {best_model_index[0]}, Learning Rate: {best_model_index[1]}, Fit Intercept: {best_model_index[2]}\")\n",
    "print(f\"MSE: {best_mse}, RMSE: {best_rmse}, R2 Score: {best_r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Depth: 1, Criterion: squared_error\n",
      "MSE: 25.064982279748, RMSE: 5.006494010757229, R2 Score: -0.011856265349853956\n",
      "---------------------------------------------------\n",
      "Max Depth: 1, Criterion: friedman_mse\n",
      "MSE: 25.064982279748, RMSE: 5.006494010757229, R2 Score: -0.011856265349853956\n",
      "---------------------------------------------------\n",
      "Max Depth: 1, Criterion: absolute_error\n",
      "MSE: 26.387208694017808, RMSE: 5.136848128377732, R2 Score: -0.06523364525612152\n",
      "---------------------------------------------------\n",
      "Max Depth: 2, Criterion: squared_error\n",
      "MSE: 24.860196428511507, RMSE: 4.986000042971471, R2 Score: -0.003589199994851633\n",
      "---------------------------------------------------\n",
      "Max Depth: 2, Criterion: friedman_mse\n",
      "MSE: 24.860196428511507, RMSE: 4.986000042971471, R2 Score: -0.003589199994851633\n",
      "---------------------------------------------------\n",
      "Max Depth: 2, Criterion: absolute_error\n",
      "MSE: 28.131257596495548, RMSE: 5.303890797942162, R2 Score: -0.13563971174971323\n",
      "---------------------------------------------------\n",
      "Max Depth: 3, Criterion: squared_error\n",
      "MSE: 25.14347131138595, RMSE: 5.01432660597472, R2 Score: -0.015024814105951467\n",
      "---------------------------------------------------\n",
      "Max Depth: 3, Criterion: friedman_mse\n",
      "MSE: 25.14347131138595, RMSE: 5.01432660597472, R2 Score: -0.015024814105951467\n",
      "---------------------------------------------------\n",
      "Max Depth: 3, Criterion: absolute_error\n",
      "MSE: 29.001184637265098, RMSE: 5.385274796820037, R2 Score: -0.17075807396420184\n",
      "---------------------------------------------------\n",
      "Max Depth: 4, Criterion: squared_error\n",
      "MSE: 26.5663014752255, RMSE: 5.154250816095924, R2 Score: -0.07246349887107306\n",
      "---------------------------------------------------\n",
      "Max Depth: 4, Criterion: friedman_mse\n",
      "MSE: 26.5663014752255, RMSE: 5.154250816095924, R2 Score: -0.07246349887107306\n",
      "---------------------------------------------------\n",
      "Max Depth: 4, Criterion: absolute_error\n",
      "MSE: 31.895383761438733, RMSE: 5.647599823061008, R2 Score: -0.28759492165394995\n",
      "---------------------------------------------------\n",
      "Max Depth: 5, Criterion: squared_error\n",
      "MSE: 28.367306724439274, RMSE: 5.326096762586958, R2 Score: -0.14516885429505666\n",
      "---------------------------------------------------\n",
      "Max Depth: 5, Criterion: friedman_mse\n",
      "MSE: 28.367306724439274, RMSE: 5.326096762586958, R2 Score: -0.14516885429505666\n",
      "---------------------------------------------------\n",
      "Max Depth: 5, Criterion: absolute_error\n",
      "MSE: 32.00298710675709, RMSE: 5.657118268761675, R2 Score: -0.2919387954264423\n",
      "---------------------------------------------------\n",
      "Max Depth: 6, Criterion: squared_error\n",
      "MSE: 31.757968281530307, RMSE: 5.635420861083075, R2 Score: -0.28204755231015666\n",
      "---------------------------------------------------\n",
      "Max Depth: 6, Criterion: friedman_mse\n",
      "MSE: 31.757968281530307, RMSE: 5.635420861083075, R2 Score: -0.28204755231015666\n",
      "---------------------------------------------------\n",
      "Max Depth: 6, Criterion: absolute_error\n",
      "MSE: 32.62335957618721, RMSE: 5.711686228793316, R2 Score: -0.31698280954292635\n",
      "---------------------------------------------------\n",
      "Max Depth: 7, Criterion: squared_error\n",
      "MSE: 33.16723609458874, RMSE: 5.7591002851651005, R2 Score: -0.3389387342102219\n",
      "---------------------------------------------------\n",
      "Max Depth: 7, Criterion: friedman_mse\n",
      "MSE: 33.16723609458874, RMSE: 5.7591002851651005, R2 Score: -0.3389387342102219\n",
      "---------------------------------------------------\n",
      "Max Depth: 7, Criterion: absolute_error\n",
      "MSE: 32.67098103885433, RMSE: 5.7158534829764776, R2 Score: -0.3189052555605234\n",
      "---------------------------------------------------\n",
      "Max Depth: 8, Criterion: squared_error\n",
      "MSE: 35.08458099929807, RMSE: 5.923223868747328, R2 Score: -0.41634064229911383\n",
      "---------------------------------------------------\n",
      "Max Depth: 8, Criterion: friedman_mse\n",
      "MSE: 35.08458099929807, RMSE: 5.923223868747328, R2 Score: -0.41634064229911383\n",
      "---------------------------------------------------\n",
      "Max Depth: 8, Criterion: absolute_error\n",
      "MSE: 33.78772524753935, RMSE: 5.812720984834844, R2 Score: -0.3639874587609666\n",
      "---------------------------------------------------\n",
      "Max Depth: 9, Criterion: squared_error\n",
      "MSE: 35.551896569096314, RMSE: 5.962541116763583, R2 Score: -0.43520585360939457\n",
      "---------------------------------------------------\n",
      "Max Depth: 9, Criterion: friedman_mse\n",
      "MSE: 35.551896569096314, RMSE: 5.962541116763583, R2 Score: -0.43520585360939457\n",
      "---------------------------------------------------\n",
      "Max Depth: 9, Criterion: absolute_error\n",
      "MSE: 34.56453755895439, RMSE: 5.879161297239122, R2 Score: -0.3953468427626581\n",
      "---------------------------------------------------\n",
      "Best Model:\n",
      "Max Depth: 2, Criterion: squared_error\n",
      "MSE: 24.860196428511507, RMSE: 4.986000042971471, R2 Score: -0.003589199994851633\n"
     ]
    }
   ],
   "source": [
    "#Decission Tree Regression\n",
    "#Import library metode machine learning.\n",
    "import warnings\n",
    "import numpy as np #operasi numerik\n",
    "import pandas as pd #analisis data\n",
    "import matplotlib.pyplot as plt #visualisasi\n",
    "from sklearn.tree import DecisionTreeRegressor #Decisiion Tree\n",
    "from sklearn.model_selection import train_test_split #membagi data\n",
    "from sklearn.metrics import mean_squared_error, r2_score #menghitung metrik\n",
    "\n",
    "#Siapkan data yang akan ditraining fitur satu \"X_feature_tiga\" dan output \n",
    "X_feature_ketiga = X[:,2:3]\n",
    "y_tiga = y\n",
    "\n",
    "#split data training dan testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_feature_ketiga, y_tiga, test_size=0.2, random_state=42) #test size 20% argument, dengan random state 42\n",
    "\n",
    "# Inisialisasi list untuk evaluasi metrik\n",
    "best_model_index = None\n",
    "best_mse = np.inf\n",
    "best_rmse = np.inf\n",
    "best_r2 = -np.inf\n",
    "\n",
    "# Hyperparameter yang akan dieksplorasi\n",
    "max_depths = range(1,10) #experiment\n",
    "criterions = ['squared_error', 'friedman_mse', 'absolute_error'] #experiment criteria\n",
    "\n",
    "#mencoba looping\n",
    "for max_depth in max_depths:\n",
    "    for criterion in criterions:\n",
    "        # membuat model decision tree regression\n",
    "        model = DecisionTreeRegressor(max_depth=max_depth, criterion=criterion)\n",
    "\n",
    "        # melatih model\n",
    "        model.fit(X_train.reshape(-1, 1), y_train)\n",
    "\n",
    "        # Prediksi\n",
    "        y_pred = model.predict(X_test.reshape(-1, 1))\n",
    "\n",
    "        # Evaluasi\n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "        rmse = np.sqrt(mse)\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "        # Hasil\n",
    "        print(f\"Max Depth: {max_depth}, Criterion: {criterion}\")\n",
    "        print(f\"MSE: {mse}, RMSE: {rmse}, R2 Score: {r2}\")\n",
    "        print(\"---------------------------------------------------\")\n",
    "\n",
    "        # Update model terbaik berdasarkan skor R2\n",
    "        if r2 > best_r2:\n",
    "            best_model_index = (max_depth, criterion)\n",
    "            best_mse = mse\n",
    "            best_rmse = rmse\n",
    "            best_r2 = r2\n",
    "\n",
    "# Detail hasil dari model terbaik\n",
    "print(\"Best Model:\")\n",
    "print(f\"Max Depth: {best_model_index[0]}, Criterion: {best_model_index[1]}\")\n",
    "print(f\"MSE: {best_mse}, RMSE: {best_rmse}, R2 Score: {best_r2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q4. process training dengan **semua fitur dan output (Multivariate)**  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1 (Fitur 1)\n",
      "MSE: 0.48944667331375896\n",
      "R2 Score: 0.9793306285005676\n",
      "-----------------------------\n",
      "Model 2 (Fitur 2)\n",
      "MSE: 23.610279820217293\n",
      "R2 Score: 0.0029360267062541467\n",
      "-----------------------------\n",
      "Model 3 (Fitur 3)\n",
      "MSE: 23.676835959871912\n",
      "R2 Score: 0.00012535569530314206\n",
      "-----------------------------\n"
     ]
    }
   ],
   "source": [
    "#Regresi Linier\n",
    "#Import library metode machine learning.\n",
    "import numpy as np #operasi numerik\n",
    "import pandas as pd #analisis data\n",
    "import matplotlib.pyplot as plt #visualisasi\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "#Siapkan data yang akan ditraining semua fitur dan output.\n",
    "X_feature_satu = X[:,:1]\n",
    "y = y\n",
    "\n",
    "X_feature_dua = X[:,1:2]\n",
    "y_dua = y\n",
    "\n",
    "X_feature_ketiga = X[:,2:3] \n",
    "y_tiga = y\n",
    "\n",
    "#split data training dan testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_feature_satu, y, test_size=0.2, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_feature_dua, y_dua, test_size=0.2, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_feature_ketiga, y_tiga, test_size=0.2, random_state=42)\n",
    "\n",
    "#inisiasi model regresi linear\n",
    "model_1 = LinearRegression()\n",
    "model_2 = LinearRegression()\n",
    "model_3 = LinearRegression()\n",
    "\n",
    "# Latih model untuk setiap kombinasi fitur dan output\n",
    "model_1.fit(X_feature_satu, y)\n",
    "model_2.fit(X_feature_dua, y_dua)\n",
    "model_3.fit(X_feature_ketiga, y_tiga)\n",
    "\n",
    "y_pred_1 = model_1.predict(X_feature_satu)\n",
    "y_pred_2 = model_2.predict(X_feature_dua)\n",
    "y_pred_3 = model_3.predict(X_feature_ketiga)\n",
    "\n",
    "mse_1 = mean_squared_error(y, y_pred_1)\n",
    "mse_2 = mean_squared_error(y_dua, y_pred_2)\n",
    "mse_3 = mean_squared_error(y_tiga, y_pred_3)\n",
    "\n",
    "r2_1 = r2_score(y, y_pred_1)\n",
    "r2_2 = r2_score(y_dua, y_pred_2)\n",
    "r2_3 = r2_score(y_tiga, y_pred_3)\n",
    "\n",
    "print(\"Model 1 (Fitur 1)\")\n",
    "print(f\"MSE: {mse_1}\")\n",
    "print(f\"R2 Score: {r2_1}\")\n",
    "print(\"-----------------------------\")\n",
    "\n",
    "print(\"Model 2 (Fitur 2)\")\n",
    "print(f\"MSE: {mse_2}\")\n",
    "print(f\"R2 Score: {r2_2}\")\n",
    "print(\"-----------------------------\")\n",
    "\n",
    "print(\"Model 3 (Fitur 3)\")\n",
    "print(f\"MSE: {mse_3}\")\n",
    "print(f\"R2 Score: {r2_3}\")\n",
    "print(\"-----------------------------\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1 (Poly Feature 1)\n",
      "MSE: 0.47310946152163263\n",
      "R2 Score: 0.9809008932264933\n",
      "-----------------------------\n",
      "Model 2 (Poly Feature 2)\n",
      "MSE: 25.478121695080517\n",
      "R2 Score: -0.02853442219838076\n",
      "-----------------------------\n",
      "Model 3 (Poly Feature 3)\n",
      "MSE: 24.48563381299255\n",
      "R2 Score: 0.011531637716049592\n",
      "-----------------------------\n"
     ]
    }
   ],
   "source": [
    "#Regresi Polinomial\n",
    "#Import library metode machine learning.\n",
    "import numpy as np #operasi numerik\n",
    "import pandas as pd #analisis data\n",
    "import matplotlib.pyplot as plt #visualisasi\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "#Siapkan data yang akan ditraining semua fitur dan output.\n",
    "X_feature_satu = X[:,:1]\n",
    "y = y\n",
    "\n",
    "X_feature_dua = X[:,1:2]\n",
    "y_dua = y\n",
    "\n",
    "X_feature_tiga = X[:,2:3] \n",
    "y_tiga = y\n",
    "#split data training dan testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_feature_satu, y, test_size=0.2, random_state=42)\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X_feature_dua, y_dua, test_size=0.2, random_state=42)\n",
    "X_train3, X_test3, y_train3, y_test3 = train_test_split(X_feature_tiga, y_tiga, test_size=0.2, random_state=42)\n",
    "\n",
    "#\n",
    "poly_transformer_satu = PolynomialFeatures(degree=2)\n",
    "X_train_poly_satu = poly_transformer_satu.fit_transform(X_train.reshape(-1, 1))  # Reshape for single feature\n",
    "X_test_poly_satu = poly_transformer_satu.transform(X_test.reshape(-1, 1))\n",
    "\n",
    "poly_transformer_dua = PolynomialFeatures(degree=2)\n",
    "X_train_poly_dua = poly_transformer_dua.fit_transform(X_train2.reshape(-1, 1))  # Reshape for single feature\n",
    "X_test_poly_dua = poly_transformer_dua.transform(X_test.reshape(-1, 1))\n",
    "\n",
    "poly_transformer_tiga = PolynomialFeatures(degree=2)\n",
    "X_train_poly_tiga = poly_transformer_tiga.fit_transform(X_train3.reshape(-1, 1))  # Reshape for single feature\n",
    "X_test_poly_tiga = poly_transformer_tiga.transform(X_test.reshape(-1, 1))\n",
    "\n",
    "#Training Data\n",
    "model_poly_satu = LinearRegression()\n",
    "model_poly_satu.fit(X_train_poly_satu, y_train)\n",
    "y_pred_poly_satu = model_poly_satu.predict(X_test_poly_satu)\n",
    "\n",
    "model_poly_dua = LinearRegression()\n",
    "model_poly_dua.fit(X_train_poly_dua, y_train2)\n",
    "y_pred_poly_dua = model_poly_dua.predict(X_test_poly_dua)\n",
    "\n",
    "model_poly_tiga = LinearRegression()\n",
    "model_poly_tiga.fit(X_train_poly_tiga, y_train3)\n",
    "y_pred_poly_tiga = model_poly_tiga.predict(X_test_poly_tiga)\n",
    "\n",
    "#Lakukan berulang kali process fitting dengan mengganti hyperparameter dan mengukur kinerjanya sehingga mendaparkan model terbaik regresi linier.\n",
    "mse_poly_satu = mean_squared_error(y_test, y_pred_poly_satu)\n",
    "r2_poly_satu = r2_score(y_test, y_pred_poly_satu)\n",
    "\n",
    "mse_poly_dua = mean_squared_error(y_test, y_pred_poly_dua)\n",
    "r2_poly_dua = r2_score(y_test2, y_pred_poly_dua)\n",
    "\n",
    "mse_poly_tiga = mean_squared_error(y_test, y_pred_poly_tiga)\n",
    "r2_poly_tiga = r2_score(y_test3, y_pred_poly_tiga)\n",
    "\n",
    "#ukur kinerja setiap model pada setiap trainig dengan MSE,RMSE, R2.\n",
    "\n",
    "print(\"Model 1 (Poly Feature 1)\")\n",
    "print(f\"MSE: {mse_poly_satu}\")\n",
    "print(f\"R2 Score: {r2_poly_satu}\")\n",
    "print(\"-----------------------------\")\n",
    "\n",
    "print(\"Model 2 (Poly Feature 2)\")\n",
    "print(f\"MSE: {mse_poly_dua}\")\n",
    "print(f\"R2 Score: {r2_poly_dua}\")\n",
    "print(\"-----------------------------\")\n",
    "\n",
    "print(\"Model 3 (Poly Feature 3)\")\n",
    "print(f\"MSE: {mse_poly_tiga}\")\n",
    "print(f\"R2 Score: {r2_poly_tiga}\")\n",
    "print(\"-----------------------------\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1 (Decision Tree Feature 1)\n",
      "MSE: 0.25235981803799457\n",
      "R2 Score: 0.9898124060031508\n",
      "-----------------------------\n",
      "Model 2 (Decision Tree Feature 2)\n",
      "MSE: 34.86540881408248\n",
      "R2 Score: -0.4074928104384865\n",
      "-----------------------------\n",
      "Model 3 (Decision Tree Feature 3)\n",
      "MSE: 55.01325397242721\n",
      "R2 Score: -1.2208475987736809\n",
      "-----------------------------\n"
     ]
    }
   ],
   "source": [
    "#Decision Tree Regresi\n",
    "#Import library metode machine learning.\n",
    "import numpy as np #operasi numerik\n",
    "import pandas as pd #analisis data\n",
    "import matplotlib.pyplot as plt #visualisasi\n",
    "from sklearn.tree import DecisionTreeRegressor #Decisiion Tree\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "#Siapkan data yang akan ditraining semua fitur dan output.\n",
    "X_feature_satu = X[:,:1]\n",
    "y = y\n",
    "\n",
    "X_feature_dua = X[:,1:2]\n",
    "y_dua = y\n",
    "\n",
    "X_feature_ketiga = X[:,2:3] \n",
    "y_tiga = y\n",
    "#split data training dan testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_feature_satu, y, test_size=0.2, random_state=42)\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X_feature_dua, y_dua, test_size=0.2, random_state=42)\n",
    "X_train3, X_test3, y_train3, y_test3 = train_test_split(X_feature_ketiga, y_tiga, test_size=0.2, random_state=42)\n",
    "\n",
    "#Gunakan data trainig untuk fitting dan data testing untuk ukuran kinerja.\n",
    "# Model for feature 1\n",
    "model_dt_satu = DecisionTreeRegressor()\n",
    "model_dt_satu.fit(X_train.reshape(-1, 1), y_train)\n",
    "y_pred_dt_satu = model_dt_satu.predict(X_test.reshape(-1, 1))\n",
    "\n",
    "# Model for feature 2 \n",
    "model_dt_dua = DecisionTreeRegressor()\n",
    "model_dt_dua.fit(X_train2.reshape(-1, 1), y_train2)\n",
    "y_pred_dt_dua = model_dt_dua.predict(X_test2.reshape(-1, 1))\n",
    "\n",
    "# Model for feature 3\n",
    "model_dt_tiga = DecisionTreeRegressor()\n",
    "model_dt_tiga.fit(X_train3.reshape(-1, 1), y_train3)\n",
    "y_pred_dt_tiga = model_dt_tiga.predict(X_test3.reshape(-1, 1))\n",
    "\n",
    "#Training dengan menggunakan metode Decision Tree Regresi. \n",
    "\n",
    "mse_dt_satu = mean_squared_error(y_test, y_pred_dt_satu)\n",
    "r2_dt_satu = r2_score(y_test, y_pred_dt_satu)\n",
    "\n",
    "mse_dt_dua = mean_squared_error(y_test2, y_pred_dt_dua)\n",
    "r2_dt_dua = r2_score(y_test2, y_pred_dt_dua)\n",
    "\n",
    "mse_dt_tiga = mean_squared_error(y_test3, y_pred_dt_tiga)\n",
    "r2_dt_tiga = r2_score(y_test3, y_pred_dt_tiga)\n",
    "\n",
    "#ukur kinerja setiap model pada setiap trainig dengan MSE,RMSE, R2.\n",
    "\n",
    "print(\"Model 1 (Decision Tree Feature 1)\")\n",
    "print(f\"MSE: {mse_dt_satu}\")\n",
    "print(f\"R2 Score: {r2_dt_satu}\")\n",
    "print(\"-----------------------------\")\n",
    "\n",
    "print(\"Model 2 (Decision Tree Feature 2)\")\n",
    "print(f\"MSE: {mse_dt_dua}\")\n",
    "print(f\"R2 Score: {r2_dt_dua}\")\n",
    "print(\"-----------------------------\")\n",
    "\n",
    "print(\"Model 3 (Decision Tree Feature 3)\")\n",
    "print(f\"MSE: {mse_dt_tiga}\")\n",
    "print(f\"R2 Score: {r2_dt_tiga}\")\n",
    "print(\"-----------------------------\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q5. Tentukan **metode dan hyperparameter** mana yang yang paling bagus untuk setiap percobaan fitur diatas? Tentukan untuk setiap fitur."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jawaban...\n",
    "Dari fitur 1 : Untuk Regresi linear bekerja dengan baik untuk fitur yang pertama, karena nilai yang dihasilkan untuk R2 bagus (0.981) dan kita melakukan pengulangan untuk mendapatkan nilai tertinggi yang cepat. Diatas kami menggunakan dua hypermater yaitu learnign rate dan fit intercept. Jika dilihat hasil dari metode regresi linear lebih bagus menggunakan hyperparamter yang fit inrecept. Fit Intercept yang menghasilkan = true untuk mencapai performa yang terbaik pada regresi linear untuk fitur pertama\n",
    "\n",
    "Dari fitur 2 : Untuk regresi decision tree tampaknya lebih cocok untuk fitur ini dibandingkan dengan regresi lainnya, karena nilai R2 yang dihasilkan lebih tinggi dibandingkan nilai R2 metode lainnya yaitu 0.023. Dengan hyperparamter yang kami kombinasikan antara penggunaan max dept dan criteria. Maka menurut kami hyperparameter yang bagus untuk fitur 2 yang menggunakan regresi decision tree adalah criteriion.\n",
    "\n",
    "Dari fitur 3 : Untuk Regresi linear bekerja dengan baik untuk fitur yang ketiga, karena nilai yang dihasilkan untuk R2 bagus (-0.02) dan kita melakukan pengulangan untuk mendapatkan nilai tertinggi yang cepat. Diatas kami menggunakan dua hypermater yaitu learnign rate dan fit intercept. Jika dilihat hasil dari metode regresi linear lebih bagus menggunakan hyperparamter yang fit inrecept. Fit Intercept yang menghasilkan = false untuk mencapai performa yang terbaik pada regresi linear untuk fitur ketiga. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q6. Tentukan **fitur mana** yang sangat bagus untuk **memprediksi harga rumah tentukan dengan nilai kinerja.** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jawaban...\n",
    "\n",
    "Jika dilihat dari hasil atau nilai kinerja setiap fitur. lebih baik menggunakan fitur 1 dikarenakan dalam penggunana setiap metode baik regresi linear, regresi polinomial, maupun decission tree tidak menghasilkan R2 negatif, melainkan menghasilkan R2 yang mendekati angka 1 atau positif (mampu menjelaskan sebagian besar variabilitas variabel dependen). Metode yang terbaik digunakan pada fitur 1 yaitu metode regresi linear dengan hyperparameter fit_intercept = true."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q7. Analisi seluruh hasil percobaan diatas. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jawaban...\n",
    "\n",
    "Jika dilihat dari 3 fitur dengan penggunana metode regresi linear, regresi polinomial, dan regresi decission tree, kami dapat menganalisis bahwa sedikit susah untuk mendapatkan fitur yang bagus jika masih mengkombinasikan hyperpamater yang ingin digunakan di setiap metodenya. Contohnya pada metode regresi linear, kami disini menggunakan hyperparameter learning rate dan fit_intercept. Dan didapatkan hyperpamater fit_intercept yang terbaik untuk metode regresi linear dalam percobaan fitur 1. Dengan hasil R2nya adalah 0.981\n",
    "\n",
    "Sedangkan untuk fitur 2, dilhat dari hasil percobaan metode dan hyperparameter yang digunakan, kami memutuskan untuk penggunaan decission tree dengan hyperparameter maxdepthnya = 6 (kanena best model yang dihasilkan yaitu 6). Walaupun kami mengkombinasikan antara hyperparameter maxdepth dan criterion, tapi menurut kami lebih cocok penggunana maxdepth dibandingkan criterion. Dengan hasil R2 nya adalah 0.023.\n",
    "\n",
    "Dan untuk fitur 3, dilihat dari hasil percobaan metode dan hyperparamter yang digunakan, kami memutuskan untuk penggunana regresi linear denmgan hyperparamter fit_intercept. dikarenakan nilai R2 yang dihasilkan lebih tinggi, walaupun dalma kondisi negatif. Serta penggunaan hyperparameter fit_intercept yang menghasilkan False.\n",
    "\n",
    "Hal tersebut disimpulkan tergantung fitur apa yang kita inisiasi, maka metode yang digunakan akan menyesuaikan parameter tersebut walaupun dengan kodingan metode A, belum tentu di fitur X lebih bagus dibandingkan di fitur Y. Sebaliknya seperti itu. Sehingga kita harus mencoba dengan baik semua metode dengan hyperparameter untuk mendapatkan nilai R2 yang terbaik (bisa dalam bentuk pemilihan hyperparameter ataupun pengulangan seperti kami)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Metode Klasifikasi dan Ensamble Learning (60%)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pada soal nomer tiga ini akan digunakan dataset dari sklearn yaitu klasifikasi kualitas wine. \n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_wine.html#sklearn.datasets.load_wine\n",
    "\n",
    "Keterangan dataset:\n",
    "1. Classes: 3 (angka 0-2)\n",
    "2. Samples per class [59,71,48]\n",
    "3. Samples total: 178\n",
    "4. Dimensionality: 13\n",
    "5. Features: real, positive\n",
    "\n",
    "https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ketentuan pengerjaan\n",
    "1. Setiap kelompok hanya menggunakan fitur sesuai ketentuan:\n",
    "    - Fitur  Alcohol, Malic acid dan  Ash\n",
    "    - Sisah fitur lainnya menyesuaikan nomer belakang nim setiap anggota kelompok, misalkan nim anggota 11590012, 115090009, 115090008 maka fitur yang digunakan adalah Flavanoids (2),Proline (8),Alcalinity of ash(9), Fitur  Alcohol, Malic acid dan  Ash (Wajib)\n",
    "\n",
    "    \n",
    "\n",
    "    0. Magnesium\n",
    "\n",
    "    1. Total phenols\n",
    "\n",
    "    2. Flavanoids\n",
    "\n",
    "    3. Nonflavanoid phenols\n",
    "\n",
    "    4. Proanthocyanins\n",
    "\n",
    "    5. Color intensity\n",
    "\n",
    "    6. Hue\n",
    "\n",
    "    7. OD280/OD315 of diluted wines\n",
    "\n",
    "    8. Proline\n",
    "\n",
    "    9. Alcalinity of ash\n",
    "\n",
    "\n",
    "2. Training dataset dengan menggunakan regresi logistik dan hitung ukuran kinerja cari hyperparameter untuk model terbaik.\n",
    "3. Training dataset dengan menggunakan decision tree dan hitung ukuran kinerja cari hyperparameter untuk model terbaik.\n",
    "4. Training dataset dengan menggunakan ensamble learning dari  regresi logistik dan decision tree dan hitung ukuran kinerja cari hyperparameter untuk model terbaik.\n",
    "5. Apakah kinerja ensamble learning diatas lebih baik dari individu classifier diatas.\n",
    "6. Training dataset dengan menggunakan ensamble learning dengan bagging dan classifier decision tree didalamnya dengan jumlah estimator atau predictior 300.\n",
    "7. Training dataset dengan menggunakan random forest dengan jumlah estimator sama dengan soal nomer 7.\n",
    "8. Bandingkan kinerja ensamble learning bagging dan decision tree dengan random forest.\n",
    "\n",
    "Berikut poin-poin penilaian untuk soal:\n",
    "1. Implementasi code untuk process training benar `(40%)`.\n",
    "2. Process perncarian hyperparameter yang tepat untuk setiap metode`(10%)`.\n",
    "3. Hyperparameter terbaik dari semua metode, model/metode terbaik bedasarkan hasil model setiap process training dengan melihat ukuran kinerja accuracy,confusion matrix, precision, recall, dan F1 score.`(30%)`.\n",
    "4. Analisis hyperparameter terbaik dari semua metode, model/metode terbaik yang dilakukan`(10%) `."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Load dataset\n",
    "Cara load dataset ada dilink berikut https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_wine.html#sklearn.datasets.load_wine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A. Load dataset\n",
    "from sklearn.datasets import load_wine\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Pilih dataset disesuaikan dengan kelas yang ingin diklasifikasi dengan ketentuan diatas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Index fitur\n",
    "\n",
    "0. Alcohol\n",
    "\n",
    "1. Malic acid\n",
    "\n",
    "2. Ash\n",
    "\n",
    "3. Alcalinity of ash\n",
    "\n",
    "4. Magnesium\n",
    "\n",
    "5. Total phenols\n",
    "\n",
    "6. Flavanoids\n",
    "\n",
    "7. Nonflavanoid phenols\n",
    "\n",
    "8. Proanthocyanins\n",
    "\n",
    "9. Color intensity\n",
    "\n",
    "10. Hue\n",
    "\n",
    "11. OD280/OD315 of diluted wines\n",
    "\n",
    "12. Proline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C. Pilih dataset dengan memilih spesifikasi fitur yang diinginkan.\n",
    "\n",
    "data = load_wine()\n",
    "X = data.data\n",
    "X_selected = X[:, [0, 1, 2, 4, 7]]\n",
    "y = data.target\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q1.Training dataset dengan menggunakan regresi logistik (softmax regression) dan hitung ukuran kinerja cari hyperparameter untuk model terbaik."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9166666666666666\n",
      "Confusion Matrix:\n",
      " [[13  0  1]\n",
      " [ 0 14  0]\n",
      " [ 1  1  6]]\n",
      "Precision: 0.9145502645502646\n",
      "Recall: 0.9166666666666666\n",
      "F1 Score: 0.914367816091954\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ananda\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "#Regresi logistik\n",
    "\n",
    "#Import library metode machine learning.\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score\n",
    "\n",
    "#Siapkan data yang akan ditraining fitur semua fitur dan output kelasnya\n",
    "wine = load_wine()\n",
    "X = wine.data\n",
    "X_selected = X[:, [0, 1, 2, 4, 7]]\n",
    "y = wine.target\n",
    "\n",
    "#Split data training dan testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.2, random_state=42)\n",
    "\n",
    "#Gunakan data training untuk fitting dan data testing untuk ukuran kinerja.\n",
    "#Training dengan menggunakan metode Regresi logistik. \n",
    "softmax = LogisticRegression(max_iter = 1000, fit_intercept = True, random_state = 0, solver = 'lbfgs')\n",
    "softmax.fit(X_train, y_train)\n",
    "y_predict_SR = softmax.predict(X_test)\n",
    "\n",
    "#Lakukan berulang kali process fitting dengan mengganti hyperparameter dan mengukur kinerjanya sehingga mendaparkan model terbaik regresi linier.\n",
    "\n",
    "#ukur kinerja setiap model pada setiap trainig dengan accuracy,confusion matrix, precision, recall, dan F1 score .\n",
    "akurasiSR = accuracy_score(y_test, y_predict_SR)\n",
    "matrixSR = confusion_matrix(y_test, y_predict_SR)\n",
    "presisiSR = precision_score(y_test, y_predict_SR, average='weighted')\n",
    "recallSR = recall_score(y_test, y_predict_SR, average='weighted')\n",
    "f1SR = f1_score(y_test, y_predict_SR, average='weighted')\n",
    "\n",
    "print(\"Accuracy:\", akurasiSR)\n",
    "print(\"Confusion Matrix:\\n\", matrixSR)\n",
    "print(\"Precision:\", presisiSR)\n",
    "print(\"Recall:\", recallSR)\n",
    "print(\"F1 Score:\", f1SR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q2.Training dataset dengan menggunakan decision tree dan hitung ukuran kinerja cari hyperparameter untuk model terbaik."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8611111111111112\n",
      "Confusion Matrix:\n",
      " [[11  2  1]\n",
      " [ 0 14  0]\n",
      " [ 2  0  6]]\n",
      "Precision: 0.8598137973137974\n",
      "Recall: 0.8611111111111112\n",
      "F1 Score: 0.8576131687242798\n"
     ]
    }
   ],
   "source": [
    "#Decision tree\n",
    "\n",
    "#Import library metode machine learning.\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score\n",
    "\n",
    "#Siapkan data yang akan ditraining fitur semua fitur dan output kelasnya\n",
    "wine = load_wine()\n",
    "X = wine.data\n",
    "X_selected = X[:, [0, 1, 2, 4, 7]]\n",
    "y = wine.target\n",
    "\n",
    "#Split data training dan testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.2, random_state=42)\n",
    "\n",
    "#Training dengan menggunakan metode Decision tree. \n",
    "#Lakukan berulang kali process fitting dengan mengganti hyperparameter dan mengukur kinerjanya sehingga mendaparkan model terbaik regresi linier.\n",
    "DTC = DecisionTreeClassifier(criterion = 'gini', max_depth = 10, random_state = 5)\n",
    "DTC.fit(X_train, y_train)\n",
    "y_predict_DT = DTC.predict(X_test)\n",
    "\n",
    "#Ukur kinerja setiap model pada setiap training dengan accuracy,confusion matrix, precision, recall, dan F1 score .\n",
    "akurasiDT = accuracy_score(y_test, y_predict_DT)\n",
    "matrixDT = confusion_matrix(y_test, y_predict_DT)\n",
    "presisiDT = precision_score(y_test, y_predict_DT, average='weighted')\n",
    "recallDT = recall_score(y_test, y_predict_DT, average='weighted')\n",
    "f1DT = f1_score(y_test, y_predict_DT, average='weighted')\n",
    "\n",
    "print(\"Accuracy:\", akurasiDT)\n",
    "print(\"Confusion Matrix:\\n\", matrixDT)\n",
    "print(\"Precision:\", presisiDT)\n",
    "print(\"Recall:\", recallDT)\n",
    "print(\"F1 Score:\", f1DT)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q3.Training dataset dengan menggunakan ensamble learning dari  regresi logistik dan decision tree dan hitung ukuran kinerja cari hyperparameter untuk model terbaik."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8888888888888888\n",
      "Confusion Matrix:\n",
      " [[13  1  0]\n",
      " [ 0 14  0]\n",
      " [ 2  1  5]]\n",
      "Precision: 0.899537037037037\n",
      "Recall: 0.8888888888888888\n",
      "F1 Score: 0.8825621377345515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ananda\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "#Ensamble learning dari regresi logistik dan decision tree.\n",
    "\n",
    "#Import library metode machine learning.\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score\n",
    "\n",
    "#Siapkan data yang akan ditraining fitur semua fitur dan output kelasnya\n",
    "wine = load_wine()\n",
    "X = wine.data\n",
    "X_selected = X[:, [0, 1, 2, 4, 7]]\n",
    "y = wine.target\n",
    "\n",
    "#Split data training dan testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.2, random_state=42)\n",
    "\n",
    "#Gunakan data training untuk fitting dan data testing untuk ukuran kinerja.\n",
    "softmax = LogisticRegression(max_iter = 1000, fit_intercept = True, random_state = 0, solver = 'lbfgs')\n",
    "DTC = DecisionTreeClassifier(criterion = 'gini', max_depth = 10, random_state = 5)\n",
    "ensemble_learning = VotingClassifier(estimators=[('lr', softmax), ('dt', DTC)], voting='hard')\n",
    "\n",
    "#Training dengan menggunakan metode Ensamble learning dari regresi logistik dan decision tree. \n",
    "#Lakukan berulang kali process fitting dengan mengganti hyperparameter dan mengukur kinerjanya sehingga mendaparkan model terbaik regresi linier.\n",
    "ensemble_learning.fit(X_train, y_train)\n",
    "y_predictEL = ensemble_learning.predict(X_test)\n",
    "\n",
    "#Ukur kinerja setiap model pada setiap trainig dengan accuracy,confusion matrix, precision, recall, dan F1 score .\n",
    "akurasiEL = accuracy_score(y_test, y_predictEL)\n",
    "matrixEL = confusion_matrix(y_test, y_predictEL)\n",
    "presisiEL = precision_score(y_test, y_predictEL, average='weighted')\n",
    "recallEL = recall_score(y_test, y_predictEL, average='weighted')\n",
    "f1EL = f1_score(y_test, y_predictEL, average='weighted')\n",
    "\n",
    "print(\"Accuracy:\", akurasiEL)\n",
    "print(\"Confusion Matrix:\\n\", matrixEL)\n",
    "print(\"Precision:\", presisiEL)\n",
    "print(\"Recall:\", recallEL)\n",
    "print(\"F1 Score:\", f1EL)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q4. Apakah kinerja ensamble learning diatas lebih baik dari individu classifier diatas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jawaban:\n",
    "\n",
    "Dari data diatas, dapat dilihat bahwa accuracy dari Regresi Logistik memiliki nilai sebesar 91.66% dan untuk Decision Tree Classifier memiliki akurasi sebesar 81.6%. Dari data tersebut dapat disimpulkan bahwa akurasi Regresi Logistik lebih baik dibandingkan Decision tree classifier berdasarkan nilai dari accuracy yang didapat. Jika dibandingkan dengan ensemble learning menggunakan Ensamble Learning. Akurasi yang diperoleh menggunakan Regresi Logistik tetap lebih besar dibandingkan dengan Ensamble Learning karena akurasi Regresi Logistik memiliki nilai sebesar 91.66% sedangkan Ensamble Learning yaitu 88.88%.\n",
    "\n",
    "Jika dilihat dari setiap metode, nilai dari F1 Score dengan metode Logistik regression lebih unggul yaitu 91.43% dan disusul oleh ensamble learning dengan skor 88.25%, sedangkan decision tree yaitu 85.76%.\n",
    "Untuk nilai recall dengan metode Logistik regression lebih unggul yaitu 91.66% dan disusul oleh ensamble learning dengan skor 88.88%, sedangkan decision tree yaitu 86.11%.\n",
    "Untuk nilai precision dengan metode Logistik regression lebih unggul yaitu 91.45% dan disusul oleh ensamble learning dengan skor 89.95%, sedangkan decision tree yaitu 85.98%.\n",
    "\n",
    "Kesimpulan yang didapat dari kinerjanya tiap metode, Regresi Logistik memimpin dari seluruh skor yang didapat dan disusul oleh ensamble learning, dan yang paling rendah yaitu decision tree. Sehingga didapat bahwa ensamble learning tidak selalu lebih baik dari individu classifier terutama logistik regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q5.Training dataset dengan menggunakan ensamble learning dengan bagging dan classifier decision tree didalamnya dengan jumlah estimator atau predictor 300."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagging Accuracy: 0.8611111111111112\n",
      "Confusion Matrix:\n",
      " [[13  1  0]\n",
      " [ 0 12  2]\n",
      " [ 2  0  6]]\n",
      "Precision: 0.8626780626780627\n",
      "Recall: 0.8611111111111112\n",
      "F1 Score: 0.8610046828437633\n"
     ]
    }
   ],
   "source": [
    "#Bagging learning dari decision tree.\n",
    "\n",
    "#Import library metode machine learning.\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score\n",
    "\n",
    "#Siapkan data yang akan ditraining fitur semua fitur dan output kelasnya\n",
    "wine = load_wine()\n",
    "X = wine.data\n",
    "X_selected = X[:, [0, 1, 2, 4, 7]]\n",
    "y = wine.target\n",
    "\n",
    "#Split data training dan testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.2, random_state=42)\n",
    "\n",
    "#Gunakan data trainig untuk fitting dan data testing untuk ukuran kinerja.\n",
    "#Training dengan menggunakan metode Bagging learning dari decision tree. \n",
    "decisiontree = DecisionTreeClassifier(criterion = 'gini', max_depth = 10, random_state = 5)\n",
    "bagging = BaggingClassifier(decisiontree, n_estimators=300)\n",
    "bagging.fit(X_train, y_train)\n",
    "\n",
    "#Lakukan berulang kali process fitting dengan mengganti hyperparameter dan mengukur kinerjanya sehingga mendaparkan model terbaik regresi linier.\n",
    "y_predict_bagging = bagging.predict(X_test)\n",
    "\n",
    "#Ukur kinerja setiap model pada setiap trainig dengan accuracy,confusion matrix, precision, recall, dan F1 score .\n",
    "akurasi_bagging = accuracy_score(y_test, y_predict_bagging)\n",
    "matrix_bagging = confusion_matrix(y_test, y_predict_bagging)\n",
    "presisi_bagging = precision_score(y_test, y_predict_bagging, average='weighted')\n",
    "recall_bagging = recall_score(y_test, y_predict_bagging, average='weighted')\n",
    "f1_bagging = f1_score(y_test, y_predict_bagging, average='weighted')\n",
    "\n",
    "print(\"Bagging Accuracy:\", akurasi_bagging)\n",
    "print(\"Confusion Matrix:\\n\", matrix_bagging)\n",
    "print(\"Precision:\", presisi_bagging)\n",
    "print(\"Recall:\", recall_bagging)\n",
    "print(\"F1 Score:\", f1_bagging)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q6.Training dataset dengan menggunakan random forest dengan jumlah estimator sama dengan soal sebelumnya."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 0.9166666666666666\n",
      "Confusion Matrix:\n",
      " [[14  0  0]\n",
      " [ 0 14  0]\n",
      " [ 2  1  5]]\n",
      "Precision: 0.9254629629629628\n",
      "Recall: 0.9166666666666666\n",
      "F1 Score: 0.909382061106199\n"
     ]
    }
   ],
   "source": [
    "#Random forest.\n",
    "\n",
    "#Import library metode machine learning.\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score\n",
    "\n",
    "#Siapkan data yang akan ditraining fitur semua fitur dan output kelasnya\n",
    "wine = load_wine()\n",
    "X = wine.data\n",
    "X_selected = X[:, [0, 1, 2, 4, 7]]\n",
    "y = wine.target\n",
    "\n",
    "#Split data training dan testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.2, random_state=42)\n",
    "\n",
    "#Gunakan data training untuk fitting dan data testing untuk ukuran kinerja.\n",
    "#Training dengan menggunakan metode random forest. \n",
    "forest_model = RandomForestClassifier(n_estimators=300, criterion = 'gini', max_depth = 10, random_state = 5)\n",
    "forest_model.fit(X_train, y_train)\n",
    "y_predict_forest = forest_model.predict(X_test)\n",
    "\n",
    "#Lakukan berulang kali process fitting dengan mengganti hyperparameter dan mengukur kinerjanya sehingga mendaparkan model terbaik regresi linier.\n",
    "#Ukur kinerja setiap model pada setiap trainig dengan accuracy,confusion matrix, precision, recall, dan F1 score .\n",
    "akurasi_forest = accuracy_score(y_test, y_predict_forest)\n",
    "matrix_forest = confusion_matrix(y_test, y_predict_forest)\n",
    "presisi_forest = precision_score(y_test, y_predict_forest, average='weighted')\n",
    "recall_forest = recall_score(y_test, y_predict_forest, average='weighted')\n",
    "f1_forest = f1_score(y_test, y_predict_forest, average='weighted')\n",
    "\n",
    "print(\"Random Forest Accuracy:\", akurasi_forest)\n",
    "print(\"Confusion Matrix:\\n\", matrix_forest)\n",
    "print(\"Precision:\", presisi_forest)\n",
    "print(\"Recall:\", recall_forest)\n",
    "print(\"F1 Score:\", f1_forest)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q7. Bandingkan kinerja ensamble learning bagging dan decision tree dengan random forest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jawaban:\n",
    "\n",
    "Hasil kinerja ensamble learning bagging jika dibandingkan random forest, akurasi random forest rata-rata lebih besar yaitu 91.66% dibanding bagging yaitu 88.88% . \n",
    "\n",
    "Untuk Precision, random forest mengungguli yaitu 92.54% , sedangkan bagging yaitu 88.86% \n",
    "\n",
    "Untuk recall, random forest mengungguli yaitu 91.66% , sedangkan bagging yaitu 88.88% \n",
    "\n",
    "Untuk F1 Score, random forest juga mengungguli yaitu 90.93% , sedangkan bagging yaitu 88.75% \n",
    "\n",
    "Dapat disimpulkan bahwa kinerja Random Forest lebih baik dari pada Ensamble Learning Bagging.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bonus**\n",
    "\n",
    "Training dataset dengan menggunakan AdaBoast dengan jumlah estimator sama dengan soal sebelumnya."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ananda\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 0.6944444444444444\n",
      "Confusion Matrix:\n",
      " [[ 8  0  6]\n",
      " [ 0 12  2]\n",
      " [ 3  0  5]]\n",
      "Precision: 0.7571872571872571\n",
      "Recall: 0.6944444444444444\n",
      "F1 Score: 0.7136833536833538\n"
     ]
    }
   ],
   "source": [
    "#AdaBoast.\n",
    "\n",
    "#Import library metode machine learning.\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score\n",
    "\n",
    "#Siapkan data yang akan ditraining fitur semua fitur dan output kelasnya\n",
    "wine = load_wine()\n",
    "X = wine.data\n",
    "X_selected = X[:, [0, 1, 2, 4, 7]]\n",
    "y = wine.target\n",
    "\n",
    "#Split data training dan testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.2, random_state=42)\n",
    "\n",
    "#Gunakan data training untuk fitting dan data testing untuk ukuran kinerja.\n",
    "#Training dengan menggunakan metode random forest. \n",
    "adaboost_model = AdaBoostClassifier(n_estimators=300, random_state = 5)\n",
    "adaboost_model.fit(X_train, y_train)\n",
    "y_predict_ada = adaboost_model.predict(X_test)\n",
    "\n",
    "#Lakukan berulang kali process fitting dengan mengganti hyperparameter dan mengukur kinerjanya sehingga mendaparkan model terbaik regresi linier.\n",
    "#Ukur kinerja setiap model pada setiap trainig dengan accuracy,confusion matrix, precision, recall, dan F1 score .\n",
    "akurasi_ada = accuracy_score(y_test, y_predict_ada)\n",
    "matrix_ada = confusion_matrix(y_test, y_predict_ada)\n",
    "presisi_ada = precision_score(y_test, y_predict_ada, average='weighted')\n",
    "recall_ada = recall_score(y_test, y_predict_ada, average='weighted')\n",
    "f1_ada = f1_score(y_test, y_predict_ada, average='weighted')\n",
    "\n",
    "print(\"Random Forest Accuracy:\", akurasi_ada)\n",
    "print(\"Confusion Matrix:\\n\", matrix_ada)\n",
    "print(\"Precision:\", presisi_ada)\n",
    "print(\"Recall:\", recall_ada)\n",
    "print(\"F1 Score:\", f1_ada)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
